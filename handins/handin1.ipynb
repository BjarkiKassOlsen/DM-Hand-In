{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "overall-spider",
   "metadata": {},
   "source": [
    "# Data Mining - Handin 1 - Clustering \n",
    "Welcome to the handin on clustering algorithms and outlier detection. \n",
    "This handin corresponds to the topics in Week 5--9 in the course.\n",
    "\n",
    "The handin is \n",
    "* done in the chosen handin groups\n",
    "* worth 10% of the final grade\n",
    "\n",
    "For the handin, you will prepare a report in PDF format, by exporting the Jupyter notebook. \n",
    "Please submit\n",
    "1. The jupyter notebook file with your answers\n",
    "2. The PDF obtained by exporting the jupyter notebook\n",
    "\n",
    "Submit both files on Brightspace no later than **March 10th kl. 23:59**.\n",
    "\n",
    "**The grading system**: Tasks are assigned a number of points based on the difficulty and time to solve it. The sum of\n",
    "the number of points is 100. For the maximum grade you need to get at least _80 points_. The minimum grade (02 in the Danish scale)\n",
    "requires **at least** 30 points, with at least 8 points on of the first three Parts (Part 1,2,3) and 6 points in the last part (Part 4).\n",
    "\n",
    "**The exercise types**: There are three different types of exercises\n",
    "1. <span style='color: green'>**\\[Compute by hand\\]**</span> means that you should provide NO code, but show the main steps to reach the result (not all). \n",
    "2. <span style='color: green'>**\\[Motivate\\]**</span> means to provide a short answer of 1-2 lines indicating the main reasoning, e.g., the PageRank of a complete graph is 1/n in all nodes as all nodes are symmetric and are connected one another.\n",
    "3. <span style='color: green'>**\\[Describe\\]**</span> means to provide a potentially longer answer of 1-5 lines indicating the analysis of the data and the results. \n",
    "4. <span style='color: green'>**\\[Prove\\]**</span> means to provide a formal argument and NO code. \n",
    "5. <span style='color: green'>**\\[Implement\\]**</span> means to provide an implementation. Unless otherwise specified, you are allowed to use helper functions (e.g., ```np.mean```, ```itertools.combinations```, and so on). However, if the task is to implement an algorithm, by no means a call to a library that implements the same algorithm will be deemed as sufficient! \n",
    "\n",
    "<font color='red'>**!!! IMPORTANT: YOU ARE NOT ALLOWED TO USE LIBRARY FUNCTIONS (SCIPY, NUMPY etc.) UNLESS EXPLICITY MENTIONED !!!**\n",
    "</font>\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decimal-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "loaded-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT TOUCH\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 132414\n",
    "## DO NOT TOUCH\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wq = pd.read_csv(\"./data/winequality-red.csv\", sep=';')\n",
    "toy = wq[wq['quality'].isin([4, 8])].sample(n=20, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-regression",
   "metadata": {},
   "source": [
    "# Intro Excercises\n",
    "\n",
    "## Task 1.1 K-Means and DBScan\n",
    "\n",
    "### Task 1.1.1 (5 points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> the cluster assignments _for the dataset below_ using k-means and $k = 2$, with initial centroids being (0, 0) and (1,1)\n",
    "\n",
    "<font color='red'>To evaluate (i.e., only to control the correctness and not to solve the exercise) your results you can use **sklearn.cluster.KMeans**.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "annoying-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_map = {4:'Blue', 8:'Red'}\n",
    "X_kmeans = toy[[\"sulphates\", \"alcohol\"]]\n",
    "\n",
    "scaler = StandardScaler().fit(X_kmeans)\n",
    "X_scaled = scaler.transform(X_kmeans)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], alpha=0.8, c=toy['quality'].map(color_map))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "collective-matter",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "We have that, when assigning points to a cluster, it is assigned as follows:\n",
    "\n",
    "$C_i =  \\{x \\in X : \\argmin_{i} ||x - \\mu_i||^2\\}$\n",
    "\n",
    "meaning that, for each point $x \\in X$, we compute the distance to each centroid $\\mu_i$ and assign it to the cluster with the closest centroid. Thus forming the clusters $C_i$, for i assigning all the different clusters.\n",
    "\n",
    "So, for the point in the lower left corner, we have that its coordinates are $p \\approx (-0.869, -1.252)$. We compute the distance to each centroid, and we have that: \n",
    "\n",
    "$||p - \\mu_1||^2 = \\sqrt{(-0.869-0)^2 + (-1.252-0)^2}^2 = (-0.869)^2 + (-1.252)^2 = 2.323$\n",
    "\n",
    "$||p - \\mu_2||^2 = \\sqrt{(-0.869-1)^2 + (-1.252-1)^2}^2 = (-1.869)^2 + (-2.252)^2 = 8.565$\n",
    "\n",
    "So, we assign the point to the cluster with the closest centroid, which is the cluster with centroid $\\mu_1 = (0,0)$, and we have that $C_1 = \\{p\\}$.\n",
    "\n",
    "Then we go through all the other points, to assign them to a cluster. We have that:\n",
    "\n",
    "$C_1 = [(-0.751, -0.545), (-0.456, 0.199), (-0.015, -0.694), (-0.456, -0.843),$\\\n",
    "$(-0.839, -0.843), (-0.604, 0.273), (-0.103, 0.720), (0.280, -0.694), (-0.721, -0.173),$\\\n",
    "$(0.397, -0.619), (-0.780, -0.843), (-0.486, 0.794), (-0.074, 0.497), (-0.280, 0.794),$\\\n",
    "$(1.045, -1.140), (-0.869, -1.252)]$\\\n",
    "$C_2 = [(0.280, 1.389), (0.280, 2.431), (3.754, -0.991), (0.397, 1.538)]$\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d65c9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The points falling in cluster C_1 are:\n",
      " [array([-0.75082858, -0.54497977]), array([-0.456386  ,  0.19901992]), array([-0.01472213, -0.69377971]), array([-0.456386  , -0.84257965]), array([-0.83916135, -0.84257965]), array([-0.60360729,  0.27341989]), array([-0.1030549,  0.7198197]), array([ 0.27972045, -0.69377971]), array([-0.72138432, -0.17297993]), array([ 0.39749748, -0.61937974]), array([-0.78027283, -0.84257965]), array([-0.48583026,  0.79421967]), array([-0.07361064,  0.49661979]), array([-0.27972045,  0.79421967]), array([ 1.04527116, -1.14017952]), array([-0.86860561, -1.25177947])]\n",
      "\n",
      "The points falling in cluster C_2 are:\n",
      " [array([0.27972045, 1.38941942]), array([0.27972045, 2.43101898]), array([ 3.75414288, -0.99137958]), array([0.39749748, 1.53821935])]\n",
      "\n",
      "We get the following labels:\n",
      " [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      " in the same order as the points in X_scaled\n"
     ]
    }
   ],
   "source": [
    "# Setting the initial centroids\n",
    "mu1, mu2 = [0, 0], [1, 1]\n",
    "\n",
    "def clustering_k2(X, mu1, mu2):\n",
    "\n",
    "    # Initializing the clusters\n",
    "    C1, C2 = [], []\n",
    "\n",
    "    # Set an empty list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    # Loop over all the points in X_scaled using the method described above to assing each point to a cluster\n",
    "    for p in X:\n",
    "        # Distance from each centroid\n",
    "        d1 = (p[0] - mu1[0])**2 + (p[1] - mu1[1])**2\n",
    "        d2 = (p[0] - mu2[0])**2 + (p[1] - mu2[1])**2\n",
    "\n",
    "        # Assigning the point to the closest centroid\n",
    "        if d1 < d2:\n",
    "            C1.append(p)\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            C2.append(p)\n",
    "            labels.append(1)\n",
    "        \n",
    "        \n",
    "    print(f'The points falling in cluster C_1 are:\\n {C1}\\n')\n",
    "    print(f'The points falling in cluster C_2 are:\\n {C2}\\n')\n",
    "    print(f'We get the following labels:\\n {labels}\\n in the same order as the points in X_scaled')\n",
    "\n",
    "clustering_k2(X_scaled, mu1, mu2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c78f88",
   "metadata": {},
   "source": [
    "In order to evaluate the correctness of the results, we can use the sklearn.cluster.KMeans function. Which gives us the following results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "087a919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus we get that the labels are:\n",
      " [0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " in the same order as the points in X_scaled\n"
     ]
    }
   ],
   "source": [
    "# Assining the initial centroids to be used in the KMeans function below\n",
    "start_centroids = np.array([[0,0], [1,1]])\n",
    "\n",
    "# Setting up the KMeans function\n",
    "Centroids = KMeans(n_clusters=2, init=start_centroids, n_init=1, random_state=RANDOM_SEED)\n",
    "\n",
    "# Fitting the KMeans function to the data\n",
    "Centroids.fit(X_scaled)\n",
    "\n",
    "# Retrieving the labels from the KMeans function\n",
    "print(f'Thus we get that the labels are:\\n {Centroids.labels_}\\n in the same order as the points in X_scaled') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a6af2d3",
   "metadata": {},
   "source": [
    "Thus validating our clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-somerset",
   "metadata": {},
   "source": [
    "### Task 1.1.2 (2 point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> <br>\n",
    "A) Show two examples with two different initial cluster assignments that lead to a different result. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "functional-vertex",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "Two examples with two different initial cluster assignments that lead to a different result are:\n",
    "\n",
    "initial_cluster_1 = np.array([[0, 0], [1, 1]])\\\n",
    "initial_cluster_2 = np.array([[0, 0], [4, -1]])\n",
    "\n",
    "To see this, we can run the same function as above, but with the second initial cluster assignment, as we have already seen the results for the first one. Thus we get that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b87926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The points falling in cluster C_1 are:\n",
      " [array([-0.75082858, -0.54497977]), array([-0.456386  ,  0.19901992]), array([-0.01472213, -0.69377971]), array([-0.456386  , -0.84257965]), array([0.27972045, 1.38941942]), array([-0.83916135, -0.84257965]), array([0.27972045, 2.43101898]), array([-0.60360729,  0.27341989]), array([-0.1030549,  0.7198197]), array([ 0.27972045, -0.69377971]), array([-0.72138432, -0.17297993]), array([ 0.39749748, -0.61937974]), array([-0.78027283, -0.84257965]), array([-0.48583026,  0.79421967]), array([-0.07361064,  0.49661979]), array([-0.27972045,  0.79421967]), array([0.39749748, 1.53821935]), array([ 1.04527116, -1.14017952]), array([-0.86860561, -1.25177947])]\n",
      "\n",
      "The points falling in cluster C_2 are:\n",
      " [array([ 3.75414288, -0.99137958])]\n",
      "\n",
      "We get the following labels:\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " in the same order as the points in X_scaled\n"
     ]
    }
   ],
   "source": [
    "mu1, mu2 = [0,0], [4, -1]\n",
    "\n",
    "clustering_k2(X_scaled, mu1, mu2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06d68fc3",
   "metadata": {},
   "source": [
    "Showing that, with the second initial centroid assignment, we only get one point into the second cluster, and the rest of the points are assigned to the first cluster. Thus resulting in a different clustering then the first initilization of the centroids.\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-chicago",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span> <br>\n",
    "B) How you explain the difference between the two cluster assignments in point A)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unable-office",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "This difference, is caused by the fact, that our second initialization of the centroids, had the second cluster right next to the one outlier in the dataset. This resulted in all the other point except for the outlier to be assigned to the first cluster. Thus resulting in a different clustering then the first initilization of the centroids.\n",
    "\n",
    "\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "statutory-management",
   "metadata": {},
   "source": [
    "### Task 1.1.3 (5 points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> the dendrogram for the dataset of Task 1.1.1. using **average-link**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "specified-template",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "Jeg tror at vi skal genskabe plottet nedenfor...\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aba76243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Z = linkage(X_scaled, 'average')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-benjamin",
   "metadata": {},
   "source": [
    "### Task 1.1.4 (2 points)\n",
    "A) <span style='color: green'>**\\[Compute by hand\\]**</span> the density-based clustering for the dataset of Task 1.1.1 using $\\epsilon=0.35$ and $MinPts=3$. Present at least 2 iterations of the algorithm.<br> \n",
    "<font color='red'>**IMPORTANT: For this exercise you can use the DBSCAN from sklearn ONLY TO CHECK YOUR RESULTS**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e859f",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "Let's start by randomly selecting a point from the dataset. We'll choose the first point: [-0.75082858, -0.54497977], which we call point 0\n",
    "\n",
    "We now calculate the distances between this point and all other points in the dataset using the Euclidean distance formula:\n",
    "\n",
    "d = sqrt((x2 - x1)^2 + (y2 - y1)^2)\n",
    "\n",
    "\n",
    "d_0 = sqrt((-0.75082858 - (-0.75082858))^2 + (-0.54497977 -(-0.54497977)^2) = 0\n",
    "d_1 = sqrt((-0.75082858 -(-0.456386))^2 + (-0.54497977 - 0.19901992)^2) = 0.8001449666737707\n",
    "\n",
    "d2-d10 = [0.7509954222039864, 0.4186431870723032, 2.191787287971323, 0.3104325442991004, 3.1493808695420027, 0.831535991863758, 1.421030763176982, 1.0412361494023215, 0.373163299558396, 4.527034422554428, 1.1507337193253573, 0.29905292167887026, 1.3651663797841393, 1.2423983969364318, 1.419647139702712, 2.378733136316918, 1.892151419342693, 0.7165453577794116]\n",
    "\n",
    "\n",
    "We now check if there are at least min_pts (3) points within the epsilon radius of 0.35 of the first point. We have that:\n",
    "[-0.83916135 -0.84257965], [-0.78027283 -0.84257965] is within epsilon radius of 0.35 of the first point, so we assign them to the same cluster as the point chosen and classify [-0.75082858, -0.54497977] as a core point.\n",
    "\n",
    "\n",
    "We now move on to the next point in our dataset and repeat the process for each of the unvisited points in the dataset until all points have been assigned to clusters or marked as noise.\n",
    "\n",
    "For the second point: point 1: [-0.456386, 0.19901992] we have the distances to all other points:\n",
    "d_0 = sqrt((-0.75082858 - (-0.456386))^2 + (-0.54497977 - 0.19901992)^2) = 0.8001449666737707\n",
    "d_1 = sqrt((-0.456386 -(-0.456386))^2 + (0.19901992 - 0.19901992)^2) = 0\n",
    "\n",
    "d2-d10 = [0.9960713547514121, 1.0415995627365955, 1.3996083998766535, 1.1097056456194665, 2.350249459105429, 0.16495291286596545, 0.6293451159653702, 1.1571274232008908, 0.4567362412714291, 4.375569041881148, 1.1827489143896828, 1.090794358413927, 0.5959276020502993, 0.4848532318824955, 0.6208650885982008, 1.5882607251489445, 2.01207090879681, 1.5082254076828203]\n",
    "\n",
    "here only point 7: [-0.60360729,  0.27341989] is within epsilon radius, which is less than min_pts in a cluster, so we assign point 1 [-0.456386, 0.19901992] as NOISE\n",
    "\n",
    "NOISE = [point 1: [-0.456386, 0.19901992]]\n",
    "\n",
    "We keep repeating for the remaining points in the dataset and we get\n",
    "Core_points = points[0,5,9,13,16]\n",
    "\n",
    "The remaining points are classified as NOISE:\n",
    "\n",
    "NOISE = ponts[1,2,3,4,6,7,10,11,14,17,18,19]\n",
    "\n",
    "\n",
    "We now collect all objects density-reachable from a core point \n",
    "and assign them to a new cluster.\n",
    "eg.  for point 0 we can create a cluster\n",
    "\n",
    "Cluster 0: [point 0: [-0.75082858 -0.54497977], point 5: [-0.83916135 -0.84257965], point 13: [-0.78027283 -0.84257965]]\n",
    "\n",
    "furthermore since point 3: [-0.456386   -0.84257965] is density reachable from the core point point 13, we add it to the cluster\n",
    "\n",
    "We keep repeating and finally have\n",
    "\n",
    "Cluster 0: [point 0: [-0.75082858 -0.54497977], point 3: [-0.456386   -0.84257965], point 5: [-0.83916135 -0.84257965], point 13: [-0.78027283 -0.84257965]]\n",
    "\n",
    "Cluster 1: [point 8: [-0.1030549   0.7198197 ], point 14: [-0.48583026  0.79421967], point 15: [-0.07361064  0.49661979], point 16: [-0.27972045  0.79421967]]\n",
    "\n",
    "Cluster 2: [point 2: [-0.01472213 -0.69377971], point 9: [ 0.27972045 -0.69377971],  point 12: [ 0.39749748 -0.61937974]]\n",
    "\n",
    "The remaining 9 points are classified as NOISE:\n",
    "\n",
    "NOISE = ponts[1,4,6,7,10,11,17,18,19]\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a458ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\u001b[1;32m/Users/dexterlam/Desktop/handin1-kopi.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/handin1-kopi.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m distances \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/handin1-kopi.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m neighbors \u001b[39m=\u001b[39m[]\n",
      "\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/handin1-kopi.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m point \u001b[39m=\u001b[39m X_scaled[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/handin1-kopi.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_scaled)):\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/handin1-kopi.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m# Distance from each centroid\u001b[39;00m\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/handin1-kopi.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(point \u001b[39m-\u001b[39m X_scaled[p])\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "distances = []\n",
    "neighbors =[]\n",
    "\n",
    "\n",
    "point = X_scaled[0]\n",
    "for p in range(len(X_scaled)):\n",
    "        # Distance from each centroid\n",
    "        d = np.linalg.norm(point - X_scaled[p])\n",
    "        distances.append(d)\n",
    "        if d <= 0.35:\n",
    "                neighbors.append(f\" point: {[X_scaled[p],p]} with distance {d}\")\n",
    "for i in neighbors:\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-briefs",
   "metadata": {},
   "source": [
    "\n",
    "B) <span style='color: green'>**\\[Describe\\]**</span> the difference between the clusters obtained with DBSCAN and those obtained with KMeans in Task 1.1.1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-programming",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-fields",
   "metadata": {},
   "source": [
    "## Task 1.2 Elliptic data set (2 points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span> <br> \n",
    "After looking at the dataset _below_, you want to detect the red outlier point, assuming you know that it is an outlier. \n",
    "\n",
    "Which approach would be the most obvious to find the red outlier? Please (1) check the box and (2) motivate your answer below:\n",
    "- [ ] Distance based approach (with parameteres $\\pi=0.5$, $\\epsilon=2$ and euclidean distance)\n",
    "- [ ] Angle based approach\n",
    "- [ ] Depth based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspended-legend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_new = np.array([[1.0, 2.0], # Red \n",
    "                [1., 1.0],\n",
    "                [0.5, 0.5],\n",
    "                [1, 0.5],\n",
    "                [0.5, 1],\n",
    "                [0.75, 0.75]\n",
    "                 ])\n",
    "\n",
    "plt.scatter(D_new[:, 0], D_new[:, 1], alpha=0.8, c = ['red' if i == 0 else 'blue' for i in range(len(D_new))])\n",
    "plt.axis([0, 2, 0,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2321578",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "The beset approach given the dataset is the depth-based approach. The depth of a point is defined as the number of half-spaces that contain the point. The deeper a point is, the less likely it is to be an outlier. Therefore, in this case, by computing the depth of each point, we can detect the red outlier point as the point with the smallest depth.\n",
    "\n",
    "\n",
    "The other two approaches, distance-based and angle-based, may not be as effective in detecting the red outlier point in this particular dataset.\n",
    "\n",
    "Distance-based approach:\n",
    "\n",
    "With the given dataset, a distance-based approach can be used to identify the point farthest from the cluster in the dataset\n",
    "\n",
    "Angle-based approach:\n",
    "\n",
    "The angle-based approach involves computing the angle between the reference point and each other point in the dataset. The red outlier point may not be identified as an outlier in this approach because it is located close to other points that have similar angles. Additionally, selecting an appropriate reference point can be challenging and may require prior knowledge about the dataset.\n",
    "\n",
    "Therefore, in this case, the depth-based approach is more appropriate since it considers the spatial distribution of the data and the relative position of each point with respect to the others, without depending on specific parameter values or reference points.\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-extraction",
   "metadata": {},
   "source": [
    "## Task 1.3 Theoretical questions (4 points)\n",
    "<span style='color: green'>**\\[Prove\\]**</span> \n",
    "\n",
    "1. You are given a measure $d(x,y) = |x-y|$, prove that the measure is a metric \n",
    "2. Prove that $\\hat{\\Sigma}=\n",
    "\\frac{1}{n}\\sum_{i=1}^n (x_i -\\hat{\\mu}^\\top)\\cdot(x_i -\\hat{\\mu}^\\top)^\\top=E[(X-\\hat{\\mu})(X-\\hat{\\mu})^\\top]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "single-column",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "- 1. If $d(\\cdot, \\cdot)$ is a metric, it must satisfy the following axioms for all $p_i$ and $p_j$:\n",
    "\n",
    "a) $d(p_i,p_j) \\ge 0$\\\n",
    "b) $d(p_i,p_j) = 0 \\iff p_i = p_j$\\\n",
    "c) $d(p_i,p_j) = d(p_j,p_i)$\\\n",
    "d) $d(p_i,p_j) \\le d(p_i,p_k) + d(p_k,p_j)$ (the triangle inequality)\n",
    "\n",
    "Thus we need to check if our metric satisfies the criteria's above.\n",
    "\n",
    "a) $d(x,y) = |x-y| \\geq 0 \\quad \\forall x, y$\\\n",
    "b) $d(x,y) = |x-y| = 0 \\iff x = y$\\\n",
    "c) $d(x,y) = |x-y| = |y-x| = d(y,x)$\\\n",
    "d) $d(x,y) = |x-y| = |x-z+z-y| \\leq |x-z| + |z-y| = d(x,z) + d(z,y)$\n",
    "\n",
    "The first two criteria's are trivially satisfied, and the last two are also trivally satisfied by the properties of the absolute value function.\n",
    "\n",
    "- 2. Not sure if we have to prove LLN, or if we just have to show that vector multiplication can be written more compact in expectation form?\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-artwork",
   "metadata": {},
   "source": [
    "# Part 2 Exploratory data analysis\n",
    "In this section, you will perform preliminary analysis on your data. These preliminary analysis are useful to understand how the data behaves, before running complex algorithms.<br>\n",
    "\n",
    "This dataset is about red wine variants of the Portuguese \"Vinho Verde\" wine. It only contains physicochemical and sensory variables, so no prices, grape types and such. Every sample  has also a class of quality which has scores between 1 and 10. It has been used and published with [Cortez et al., 2009](http://dx.doi.org/10.1016/j.dss.2009.05.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "guilty-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.172</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>17.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.054</td>\n",
       "      <td>8.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "18            7.4             0.590         0.08             4.4      0.086   \n",
       "38            5.7             1.130         0.09             1.5      0.172   \n",
       "41            8.8             0.610         0.30             2.8      0.088   \n",
       "45            4.6             0.520         0.15             2.1      0.054   \n",
       "73            8.3             0.675         0.26             2.1      0.084   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "18                  6.0                  29.0   0.9974  3.38       0.50   \n",
       "38                  7.0                  19.0   0.9940  3.50       0.48   \n",
       "41                 17.0                  46.0   0.9976  3.26       0.51   \n",
       "45                  8.0                  65.0   0.9934  3.90       0.56   \n",
       "73                 11.0                  43.0   0.9976  3.31       0.53   \n",
       "\n",
       "    alcohol  quality  \n",
       "18      9.0        4  \n",
       "38      9.8        4  \n",
       "41      9.3        4  \n",
       "45     13.1        4  \n",
       "73      9.2        4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy = wq[wq['quality'].isin([4, 8])]\n",
    "data_np = toy.to_numpy()\n",
    "headers = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
    "X = data_np[:,:10]\n",
    "y = data_np[:,11]\n",
    "y = y.astype(int) - 1\n",
    "rows, cols = np.shape(X)\n",
    "toy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-ottawa",
   "metadata": {},
   "source": [
    "## Task 2.1 Correlation matrix\n",
    "### Task 2.1.1 (5 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span> in the code-box below the **correlation matrix** (not covariance matrix) among all the attributes. <br>\n",
    "<font color='red'>To CHECK your results you can use **numpy.corrcoef**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47cb5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.40000e+00, 5.90000e-01, 8.00000e-02, 4.40000e+00, 8.60000e-02,\n",
       "        6.00000e+00, 2.90000e+01, 9.97400e-01, 3.38000e+00, 5.00000e-01],\n",
       "       [5.70000e+00, 1.13000e+00, 9.00000e-02, 1.50000e+00, 1.72000e-01,\n",
       "        7.00000e+00, 1.90000e+01, 9.94000e-01, 3.50000e+00, 4.80000e-01],\n",
       "       [8.80000e+00, 6.10000e-01, 3.00000e-01, 2.80000e+00, 8.80000e-02,\n",
       "        1.70000e+01, 4.60000e+01, 9.97600e-01, 3.26000e+00, 5.10000e-01],\n",
       "       [4.60000e+00, 5.20000e-01, 1.50000e-01, 2.10000e+00, 5.40000e-02,\n",
       "        8.00000e+00, 6.50000e+01, 9.93400e-01, 3.90000e+00, 5.60000e-01],\n",
       "       [8.30000e+00, 6.75000e-01, 2.60000e-01, 2.10000e+00, 8.40000e-02,\n",
       "        1.10000e+01, 4.30000e+01, 9.97600e-01, 3.31000e+00, 5.30000e-01],\n",
       "       [8.30000e+00, 6.25000e-01, 2.00000e-01, 1.50000e+00, 8.00000e-02,\n",
       "        2.70000e+01, 1.19000e+02, 9.97200e-01, 3.16000e+00, 1.12000e+00],\n",
       "       [5.00000e+00, 1.02000e+00, 4.00000e-02, 1.40000e+00, 4.50000e-02,\n",
       "        4.10000e+01, 8.50000e+01, 9.93800e-01, 3.75000e+00, 4.80000e-01],\n",
       "       [9.20000e+00, 5.20000e-01, 1.00000e+00, 3.40000e+00, 6.10000e-01,\n",
       "        3.20000e+01, 6.90000e+01, 9.99600e-01, 2.74000e+00, 2.00000e+00],\n",
       "       [7.60000e+00, 6.80000e-01, 2.00000e-02, 1.30000e+00, 7.20000e-02,\n",
       "        9.00000e+00, 2.00000e+01, 9.96500e-01, 3.17000e+00, 1.08000e+00],\n",
       "       [7.30000e+00, 5.50000e-01, 3.00000e-02, 1.60000e+00, 7.20000e-02,\n",
       "        1.70000e+01, 4.20000e+01, 9.95600e-01, 3.37000e+00, 4.80000e-01],\n",
       "       [7.90000e+00, 8.85000e-01, 3.00000e-02, 1.80000e+00, 5.80000e-02,\n",
       "        4.00000e+00, 8.00000e+00, 9.97200e-01, 3.36000e+00, 3.30000e-01],\n",
       "       [6.90000e+00, 1.09000e+00, 6.00000e-02, 2.10000e+00, 6.10000e-02,\n",
       "        1.20000e+01, 3.10000e+01, 9.94800e-01, 3.51000e+00, 4.30000e-01],\n",
       "       [8.40000e+00, 6.35000e-01, 3.60000e-01, 2.00000e+00, 8.90000e-02,\n",
       "        1.50000e+01, 5.50000e+01, 9.97450e-01, 3.31000e+00, 5.70000e-01],\n",
       "       [7.00000e+00, 9.75000e-01, 4.00000e-02, 2.00000e+00, 8.70000e-02,\n",
       "        1.20000e+01, 6.70000e+01, 9.95650e-01, 3.35000e+00, 6.00000e-01],\n",
       "       [8.10000e+00, 8.70000e-01, 0.00000e+00, 3.30000e+00, 9.60000e-02,\n",
       "        2.60000e+01, 6.10000e+01, 1.00025e+00, 3.60000e+00, 7.20000e-01],\n",
       "       [7.90000e+00, 3.50000e-01, 4.60000e-01, 3.60000e+00, 7.80000e-02,\n",
       "        1.50000e+01, 3.70000e+01, 9.97300e-01, 3.35000e+00, 8.60000e-01],\n",
       "       [1.03000e+01, 3.20000e-01, 4.50000e-01, 6.40000e+00, 7.30000e-02,\n",
       "        5.00000e+00, 1.30000e+01, 9.97600e-01, 3.23000e+00, 8.20000e-01],\n",
       "       [5.60000e+00, 8.50000e-01, 5.00000e-02, 1.40000e+00, 4.50000e-02,\n",
       "        1.20000e+01, 8.80000e+01, 9.92400e-01, 3.56000e+00, 8.20000e-01],\n",
       "       [1.25000e+01, 4.60000e-01, 4.90000e-01, 4.50000e+00, 7.00000e-02,\n",
       "        2.60000e+01, 4.90000e+01, 9.98100e-01, 3.05000e+00, 5.70000e-01],\n",
       "       [1.26000e+01, 3.10000e-01, 7.20000e-01, 2.20000e+00, 7.20000e-02,\n",
       "        6.00000e+00, 2.90000e+01, 9.98700e-01, 2.88000e+00, 8.20000e-01],\n",
       "       [1.13000e+01, 6.20000e-01, 6.70000e-01, 5.20000e+00, 8.60000e-02,\n",
       "        6.00000e+00, 1.90000e+01, 9.98800e-01, 3.22000e+00, 6.90000e-01],\n",
       "       [9.40000e+00, 3.00000e-01, 5.60000e-01, 2.80000e+00, 8.00000e-02,\n",
       "        6.00000e+00, 1.70000e+01, 9.96400e-01, 3.15000e+00, 9.20000e-01],\n",
       "       [1.07000e+01, 3.50000e-01, 5.30000e-01, 2.60000e+00, 7.00000e-02,\n",
       "        5.00000e+00, 1.60000e+01, 9.97200e-01, 3.15000e+00, 6.50000e-01],\n",
       "       [1.07000e+01, 3.50000e-01, 5.30000e-01, 2.60000e+00, 7.00000e-02,\n",
       "        5.00000e+00, 1.60000e+01, 9.97200e-01, 3.15000e+00, 6.50000e-01],\n",
       "       [1.05000e+01, 5.90000e-01, 4.90000e-01, 2.10000e+00, 7.00000e-02,\n",
       "        1.40000e+01, 4.70000e+01, 9.99100e-01, 3.30000e+00, 5.60000e-01],\n",
       "       [9.90000e+00, 5.00000e-01, 2.40000e-01, 2.30000e+00, 1.03000e-01,\n",
       "        6.00000e+00, 1.40000e+01, 9.97800e-01, 3.34000e+00, 5.20000e-01],\n",
       "       [5.00000e+00, 4.20000e-01, 2.40000e-01, 2.00000e+00, 6.00000e-02,\n",
       "        1.90000e+01, 5.00000e+01, 9.91700e-01, 3.72000e+00, 7.40000e-01],\n",
       "       [8.20000e+00, 9.15000e-01, 2.70000e-01, 2.10000e+00, 8.80000e-02,\n",
       "        7.00000e+00, 2.30000e+01, 9.96200e-01, 3.26000e+00, 4.70000e-01],\n",
       "       [1.01000e+01, 9.35000e-01, 2.20000e-01, 3.40000e+00, 1.05000e-01,\n",
       "        1.10000e+01, 8.60000e+01, 1.00100e+00, 3.43000e+00, 6.40000e-01],\n",
       "       [8.30000e+00, 8.45000e-01, 1.00000e-02, 2.20000e+00, 7.00000e-02,\n",
       "        5.00000e+00, 1.40000e+01, 9.96700e-01, 3.32000e+00, 5.80000e-01],\n",
       "       [7.10000e+00, 8.40000e-01, 2.00000e-02, 4.40000e+00, 9.60000e-02,\n",
       "        5.00000e+00, 1.30000e+01, 9.97000e-01, 3.41000e+00, 5.70000e-01],\n",
       "       [7.50000e+00, 3.80000e-01, 4.80000e-01, 2.60000e+00, 7.30000e-02,\n",
       "        2.20000e+01, 8.40000e+01, 9.97200e-01, 3.32000e+00, 7.00000e-01],\n",
       "       [9.10000e+00, 7.65000e-01, 4.00000e-02, 1.60000e+00, 7.80000e-02,\n",
       "        4.00000e+00, 1.40000e+01, 9.98000e-01, 3.29000e+00, 5.40000e-01],\n",
       "       [7.50000e+00, 1.11500e+00, 1.00000e-01, 3.10000e+00, 8.60000e-02,\n",
       "        5.00000e+00, 1.20000e+01, 9.95800e-01, 3.54000e+00, 6.00000e-01],\n",
       "       [6.90000e+00, 3.90000e-01, 2.40000e-01, 2.10000e+00, 1.02000e-01,\n",
       "        4.00000e+00, 7.00000e+00, 9.94620e-01, 3.44000e+00, 5.80000e-01],\n",
       "       [7.80000e+00, 5.70000e-01, 9.00000e-02, 2.30000e+00, 6.50000e-02,\n",
       "        3.40000e+01, 4.50000e+01, 9.94170e-01, 3.46000e+00, 7.40000e-01],\n",
       "       [7.50000e+00, 6.85000e-01, 7.00000e-02, 2.50000e+00, 5.80000e-02,\n",
       "        5.00000e+00, 9.00000e+00, 9.96320e-01, 3.38000e+00, 5.50000e-01],\n",
       "       [1.16000e+01, 4.70000e-01, 4.40000e-01, 1.60000e+00, 1.47000e-01,\n",
       "        3.60000e+01, 5.10000e+01, 9.98360e-01, 3.38000e+00, 8.60000e-01],\n",
       "       [7.30000e+00, 3.50000e-01, 2.40000e-01, 2.00000e+00, 6.70000e-02,\n",
       "        2.80000e+01, 4.80000e+01, 9.95760e-01, 3.43000e+00, 5.40000e-01],\n",
       "       [7.10000e+00, 4.70000e-01, 0.00000e+00, 2.20000e+00, 6.70000e-02,\n",
       "        7.00000e+00, 1.40000e+01, 9.95170e-01, 3.40000e+00, 5.80000e-01],\n",
       "       [8.40000e+00, 6.70000e-01, 1.90000e-01, 2.20000e+00, 9.30000e-02,\n",
       "        1.10000e+01, 7.50000e+01, 9.97360e-01, 3.20000e+00, 5.90000e-01],\n",
       "       [1.20000e+01, 6.30000e-01, 5.00000e-01, 1.40000e+00, 7.10000e-02,\n",
       "        6.00000e+00, 2.60000e+01, 9.97910e-01, 3.07000e+00, 6.00000e-01],\n",
       "       [9.10000e+00, 4.00000e-01, 5.00000e-01, 1.80000e+00, 7.10000e-02,\n",
       "        7.00000e+00, 1.60000e+01, 9.94620e-01, 3.21000e+00, 6.90000e-01],\n",
       "       [1.00000e+01, 2.60000e-01, 5.40000e-01, 1.90000e+00, 8.30000e-02,\n",
       "        4.20000e+01, 7.40000e+01, 9.94510e-01, 2.98000e+00, 6.30000e-01],\n",
       "       [7.90000e+00, 5.40000e-01, 3.40000e-01, 2.50000e+00, 7.60000e-02,\n",
       "        8.00000e+00, 1.70000e+01, 9.92350e-01, 3.20000e+00, 7.20000e-01],\n",
       "       [6.50000e+00, 5.80000e-01, 0.00000e+00, 2.20000e+00, 9.60000e-02,\n",
       "        3.00000e+00, 1.30000e+01, 9.95570e-01, 3.62000e+00, 6.20000e-01],\n",
       "       [6.50000e+00, 8.80000e-01, 3.00000e-02, 5.60000e+00, 7.90000e-02,\n",
       "        2.30000e+01, 4.70000e+01, 9.95720e-01, 3.58000e+00, 5.00000e-01],\n",
       "       [8.80000e+00, 9.55000e-01, 5.00000e-02, 1.80000e+00, 7.50000e-02,\n",
       "        5.00000e+00, 1.90000e+01, 9.96160e-01, 3.30000e+00, 4.40000e-01],\n",
       "       [8.60000e+00, 4.20000e-01, 3.90000e-01, 1.80000e+00, 6.80000e-02,\n",
       "        6.00000e+00, 1.20000e+01, 9.95160e-01, 3.35000e+00, 6.90000e-01],\n",
       "       [1.02000e+01, 2.30000e-01, 3.70000e-01, 2.20000e+00, 5.70000e-02,\n",
       "        1.40000e+01, 3.60000e+01, 9.96140e-01, 3.23000e+00, 4.90000e-01],\n",
       "       [6.00000e+00, 3.30000e-01, 3.20000e-01, 1.29000e+01, 5.40000e-02,\n",
       "        6.00000e+00, 1.13000e+02, 9.95720e-01, 3.30000e+00, 5.60000e-01],\n",
       "       [8.10000e+00, 7.30000e-01, 0.00000e+00, 2.50000e+00, 8.10000e-02,\n",
       "        1.20000e+01, 2.40000e+01, 9.97980e-01, 3.38000e+00, 4.60000e-01],\n",
       "       [6.50000e+00, 6.70000e-01, 0.00000e+00, 4.30000e+00, 5.70000e-02,\n",
       "        1.10000e+01, 2.00000e+01, 9.94880e-01, 3.45000e+00, 5.60000e-01],\n",
       "       [6.30000e+00, 1.02000e+00, 0.00000e+00, 2.00000e+00, 8.30000e-02,\n",
       "        1.70000e+01, 2.40000e+01, 9.94370e-01, 3.59000e+00, 5.50000e-01],\n",
       "       [8.20000e+00, 7.80000e-01, 0.00000e+00, 2.20000e+00, 8.90000e-02,\n",
       "        1.30000e+01, 2.60000e+01, 9.97800e-01, 3.37000e+00, 4.60000e-01],\n",
       "       [5.50000e+00, 4.90000e-01, 3.00000e-02, 1.80000e+00, 4.40000e-02,\n",
       "        2.80000e+01, 8.70000e+01, 9.90800e-01, 3.50000e+00, 8.20000e-01],\n",
       "       [8.50000e+00, 4.00000e-01, 4.00000e-01, 6.30000e+00, 5.00000e-02,\n",
       "        3.00000e+00, 1.00000e+01, 9.95660e-01, 3.28000e+00, 5.60000e-01],\n",
       "       [7.50000e+00, 7.55000e-01, 0.00000e+00, 1.90000e+00, 8.40000e-02,\n",
       "        6.00000e+00, 1.20000e+01, 9.96720e-01, 3.34000e+00, 4.90000e-01],\n",
       "       [6.80000e+00, 6.80000e-01, 9.00000e-02, 3.90000e+00, 6.80000e-02,\n",
       "        1.50000e+01, 2.90000e+01, 9.95240e-01, 3.41000e+00, 5.20000e-01],\n",
       "       [8.00000e+00, 8.30000e-01, 2.70000e-01, 2.00000e+00, 8.00000e-02,\n",
       "        1.10000e+01, 6.30000e+01, 9.96520e-01, 3.29000e+00, 4.80000e-01],\n",
       "       [6.60000e+00, 6.10000e-01, 0.00000e+00, 1.60000e+00, 6.90000e-02,\n",
       "        4.00000e+00, 8.00000e+00, 9.93960e-01, 3.33000e+00, 3.70000e-01],\n",
       "       [7.20000e+00, 3.30000e-01, 3.30000e-01, 1.70000e+00, 6.10000e-02,\n",
       "        3.00000e+00, 1.30000e+01, 9.96000e-01, 3.23000e+00, 1.10000e+00],\n",
       "       [6.40000e+00, 5.30000e-01, 9.00000e-02, 3.90000e+00, 1.23000e-01,\n",
       "        1.40000e+01, 3.10000e+01, 9.96800e-01, 3.50000e+00, 6.70000e-01],\n",
       "       [7.20000e+00, 3.80000e-01, 3.10000e-01, 2.00000e+00, 5.60000e-02,\n",
       "        1.50000e+01, 2.90000e+01, 9.94720e-01, 3.23000e+00, 7.60000e-01],\n",
       "       [6.20000e+00, 7.85000e-01, 0.00000e+00, 2.10000e+00, 6.00000e-02,\n",
       "        6.00000e+00, 1.30000e+01, 9.96640e-01, 3.59000e+00, 6.10000e-01],\n",
       "       [6.70000e+00, 1.04000e+00, 8.00000e-02, 2.30000e+00, 6.70000e-02,\n",
       "        1.90000e+01, 3.20000e+01, 9.96480e-01, 3.52000e+00, 5.70000e-01],\n",
       "       [5.60000e+00, 6.20000e-01, 3.00000e-02, 1.50000e+00, 8.00000e-02,\n",
       "        6.00000e+00, 1.30000e+01, 9.94980e-01, 3.66000e+00, 6.20000e-01],\n",
       "       [7.20000e+00, 5.80000e-01, 5.40000e-01, 2.10000e+00, 1.14000e-01,\n",
       "        3.00000e+00, 9.00000e+00, 9.97190e-01, 3.33000e+00, 5.70000e-01],\n",
       "       [6.80000e+00, 9.10000e-01, 6.00000e-02, 2.00000e+00, 6.00000e-02,\n",
       "        4.00000e+00, 1.10000e+01, 9.95920e-01, 3.53000e+00, 6.40000e-01],\n",
       "       [6.90000e+00, 4.80000e-01, 2.00000e-01, 1.90000e+00, 8.20000e-02,\n",
       "        9.00000e+00, 2.30000e+01, 9.95850e-01, 3.39000e+00, 4.30000e-01],\n",
       "       [7.40000e+00, 3.60000e-01, 3.00000e-01, 1.80000e+00, 7.40000e-02,\n",
       "        1.70000e+01, 2.40000e+01, 9.94190e-01, 3.24000e+00, 7.00000e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb3ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, -0.32601657683847257, 0.6521302274742028, 0.03493438656618914, 0.1276712246300788, 0.00721408143842016, -0.09335370290670614, 0.6518393555872984, -0.7348850846057341, 0.15409619631135862, -0.20624830227625718, 0.19359054263958747], [-0.32601657683847257, 1, -0.5964048351399217, -0.18276595476303115, 0.006695121004310826, -0.05762256568603232, -0.012511707790229799, 0.030877132465994158, 0.4360812397422024, -0.3030244745590644, -0.20033037584867222, -0.5048962791868324], [0.6521302274742028, -0.5964048351399217, 1, 0.16350495835323509, 0.41314537114076105, 0.1089333169736447, 0.09817644843151146, 0.3324457672160988, -0.7024543456464125, 0.5033454599029221, 0.09151063635401442, 0.4306258751235469], [0.03493438656618914, -0.18276595476303115, 0.16350495835323509, 1, 0.019655631306707767, -0.10172705171893798, 0.18164278438037024, 0.16776100303469146, -0.07800123824680011, 0.0010805504640967426, 0.22429037784636513, -0.03058153816046265], [0.1276712246300788, 0.006695121004310826, 0.41314537114076105, 0.019655631306707767, 1, 0.22875324890174703, 0.10687776900524952, 0.311387790025916, -0.37115019043438036, 0.6745559968200553, -0.20769039837331688, -0.14618950059038924], [0.00721408143842016, -0.05762256568603232, 0.1089333169736447, -0.10172705171893798, 0.22875324890174703, 1, 0.6295026644204577, -0.07375084312801586, 0.00020474676472789156, 0.2811419413969995, 0.00999211479453455, 0.04656926719626171], [-0.09335370290670614, -0.012511707790229799, 0.09817644843151146, 0.18164278438037024, 0.10687776900524952, 0.6295026644204577, 1, -0.008714019190938168, 0.011617768590369136, 0.24911573910795035, 0.0035092496092082827, -0.045611697085719445], [0.6518393555872984, 0.030877132465994158, 0.3324457672160988, 0.16776100303469146, 0.311387790025916, -0.07375084312801586, -0.008714019190938168, 1, -0.41979416914857043, 0.14347497445564528, -0.5421349725865546, -0.3090397463833228], [-0.7348850846057341, 0.4360812397422024, -0.7024543456464125, -0.07800123824680011, -0.37115019043438036, 0.00020474676472789156, 0.011617768590369136, -0.41979416914857043, 1, -0.4284333278729068, 0.27277524793749824, -0.2612334652019338], [0.15409619631135862, -0.3030244745590644, 0.5033454599029221, 0.0010805504640967426, 0.6745559968200553, 0.2811419413969995, 0.24911573910795035, 0.14347497445564528, -0.4284333278729068, 1, 0.10304130692486414, 0.33102121000665546], [-0.20624830227625718, -0.20033037584867222, 0.09151063635401442, 0.22429037784636513, -0.20769039837331688, 0.00999211479453455, 0.0035092496092082827, -0.5421349725865546, 0.27277524793749824, 0.10304130692486414, 1, 0.6229456196183382], [0.19359054263958747, -0.5048962791868324, 0.4306258751235469, -0.03058153816046265, -0.14618950059038924, 0.04656926719626171, -0.045611697085719445, -0.3090397463833228, -0.2612334652019338, 0.33102121000665546, 0.6229456196183382, 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fa552885d60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def correlation_matrix(X):\n",
    "    corr = None\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    data = X\n",
    "    \n",
    "\n",
    "# Compute the correlation matrix\n",
    "    n = len(data)\n",
    "    means = [sum(x) / n for x in data.T]\n",
    "    stddevs = []\n",
    "    for i in range(len(data[0])):\n",
    "        std = [(x[i] - means[i])**2 for x in data]\n",
    "        stddevs.append((sum(std) / n)**0.5)\n",
    "\n",
    "\n",
    "\n",
    "    corr = [[0 for _ in range(len(data[0]))] for _ in range(len(data[0]))]\n",
    "\n",
    "\n",
    "    for i in range(len(data[0])):\n",
    "        for j in range(len(data[0])):\n",
    "            if i == j:\n",
    "                corr[i][j] = 1\n",
    "            else:\n",
    "                cov = sum((data[k][i] - means[i]) * (data[k][j] - means[j]) for k in range(n)) /n\n",
    "                corr[i][j] = cov / (stddevs[i] * stddevs[j])\n",
    "    \n",
    "\n",
    "    # YOUR CODE HERE \n",
    "    return corr\n",
    "    \n",
    "X = data_np\n",
    "Corr = correlation_matrix(X)\n",
    "print(Corr)\n",
    "plt.matshow(Corr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dea6c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -3.26016577e-01,  6.52130227e-01,\n",
       "         3.49343866e-02,  1.27671225e-01,  7.21408144e-03,\n",
       "        -9.33537029e-02,  6.51839356e-01, -7.34885085e-01,\n",
       "         1.54096196e-01, -2.06248302e-01,  1.93590543e-01],\n",
       "       [-3.26016577e-01,  1.00000000e+00, -5.96404835e-01,\n",
       "        -1.82765955e-01,  6.69512100e-03, -5.76225657e-02,\n",
       "        -1.25117078e-02,  3.08771325e-02,  4.36081240e-01,\n",
       "        -3.03024475e-01, -2.00330376e-01, -5.04896279e-01],\n",
       "       [ 6.52130227e-01, -5.96404835e-01,  1.00000000e+00,\n",
       "         1.63504958e-01,  4.13145371e-01,  1.08933317e-01,\n",
       "         9.81764484e-02,  3.32445767e-01, -7.02454346e-01,\n",
       "         5.03345460e-01,  9.15106364e-02,  4.30625875e-01],\n",
       "       [ 3.49343866e-02, -1.82765955e-01,  1.63504958e-01,\n",
       "         1.00000000e+00,  1.96556313e-02, -1.01727052e-01,\n",
       "         1.81642784e-01,  1.67761003e-01, -7.80012382e-02,\n",
       "         1.08055046e-03,  2.24290378e-01, -3.05815382e-02],\n",
       "       [ 1.27671225e-01,  6.69512100e-03,  4.13145371e-01,\n",
       "         1.96556313e-02,  1.00000000e+00,  2.28753249e-01,\n",
       "         1.06877769e-01,  3.11387790e-01, -3.71150190e-01,\n",
       "         6.74555997e-01, -2.07690398e-01, -1.46189501e-01],\n",
       "       [ 7.21408144e-03, -5.76225657e-02,  1.08933317e-01,\n",
       "        -1.01727052e-01,  2.28753249e-01,  1.00000000e+00,\n",
       "         6.29502664e-01, -7.37508431e-02,  2.04746765e-04,\n",
       "         2.81141941e-01,  9.99211479e-03,  4.65692672e-02],\n",
       "       [-9.33537029e-02, -1.25117078e-02,  9.81764484e-02,\n",
       "         1.81642784e-01,  1.06877769e-01,  6.29502664e-01,\n",
       "         1.00000000e+00, -8.71401919e-03,  1.16177686e-02,\n",
       "         2.49115739e-01,  3.50924961e-03, -4.56116971e-02],\n",
       "       [ 6.51839356e-01,  3.08771325e-02,  3.32445767e-01,\n",
       "         1.67761003e-01,  3.11387790e-01, -7.37508431e-02,\n",
       "        -8.71401919e-03,  1.00000000e+00, -4.19794169e-01,\n",
       "         1.43474974e-01, -5.42134973e-01, -3.09039746e-01],\n",
       "       [-7.34885085e-01,  4.36081240e-01, -7.02454346e-01,\n",
       "        -7.80012382e-02, -3.71150190e-01,  2.04746765e-04,\n",
       "         1.16177686e-02, -4.19794169e-01,  1.00000000e+00,\n",
       "        -4.28433328e-01,  2.72775248e-01, -2.61233465e-01],\n",
       "       [ 1.54096196e-01, -3.03024475e-01,  5.03345460e-01,\n",
       "         1.08055046e-03,  6.74555997e-01,  2.81141941e-01,\n",
       "         2.49115739e-01,  1.43474974e-01, -4.28433328e-01,\n",
       "         1.00000000e+00,  1.03041307e-01,  3.31021210e-01],\n",
       "       [-2.06248302e-01, -2.00330376e-01,  9.15106364e-02,\n",
       "         2.24290378e-01, -2.07690398e-01,  9.99211479e-03,\n",
       "         3.50924961e-03, -5.42134973e-01,  2.72775248e-01,\n",
       "         1.03041307e-01,  1.00000000e+00,  6.22945620e-01],\n",
       "       [ 1.93590543e-01, -5.04896279e-01,  4.30625875e-01,\n",
       "        -3.05815382e-02, -1.46189501e-01,  4.65692672e-02,\n",
       "        -4.56116971e-02, -3.09039746e-01, -2.61233465e-01,\n",
       "         3.31021210e-01,  6.22945620e-01,  1.00000000e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.corrcoef(X, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-volume",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "B) By observing the  **correlation matrix** in point A), which pair of different attributes has the highest correlation? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47547d6c",
   "metadata": {},
   "source": [
    "*******************\n",
    "By observing the correlation matrix, we can see that the pair of attributes with the highest positive correlation is chlorides and sulphates. The correlation coefficient between these two attributes is 0,6746, which is the highest among all the pairs of attributes in the dataset.\n",
    "\n",
    "The pair of attributes with the highest negative correlation is fixed acidity and pH. The correlation coefficient between these two attributes is -0.7349.\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db12e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([4, 9]), array([9, 4]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6745559968200553"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(Corr)):\n",
    "    for j in range(len(Corr[i])):\n",
    "        if Corr[i][j]==1:\n",
    "            Corr[i][j]=0\n",
    "\n",
    "\n",
    "print(np.where(Corr == np.amax(Corr)))\n",
    "np.max(Corr)\n",
    "\n",
    "print(Corr[5][6])\n",
    "Corr[9][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-senator",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "C) What does it mean that two attributs are highly correlated? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525b8ab",
   "metadata": {},
   "source": [
    "*******************\n",
    "If two attributes are highly correlated, it means that changes in one variable are associated with changes in the other variable. In other words, when one attribute changes, there is a tendency for the other attribute to change as well. This indicates a relationship between the two attributes and they are probably influenced by similar underlying factors.\n",
    "\n",
    "If the correlation coefficient between two variables is close to 1, it indicates a strong positive correlation, which means that an increase in one variable is associated with an increase in the other variable. On the other hand, if the correlation coefficient is close to -1, it indicates a strong negative correlation, which means that an increase in one variable is associated with a decrease in the other variable.\n",
    "\n",
    "If the correlation coefficient is close to 0, it indicates that there is no linear relationship between the two variables.\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-springfield",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "D) Based on the attributes of the data in Part 2 and your answer in C), did you expect the observation of B)? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ef3ee4",
   "metadata": {},
   "source": [
    "*******************\n",
    "The correlation between chlorides and sulphates does make somehow make sense since they are both type of salts which probably came from a common source. Therefore when the concentration of one of these two attributes increases, the concentration of the other attribute is also likely to increase.\n",
    "\n",
    "The negative correlation between fixed acidity and pH can also make sense because these two attributes are related to the acidity of the wine. Fixed acidity refers to the amount of acid in the wine, while pH is a measure of the acidity level of the wine. Higher fixed acidity indicates more acid in the wine, which would result in a lower pH. Therefore, it is reasonable to expect that these two attributes would be negatively correlated.\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-content",
   "metadata": {},
   "source": [
    "### Task 2.1.2 (1 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Plot the correlation matrix running the code below.\n",
    "What is the relationship between the correlation matrix and the covariance matrix? (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "- [ ] The correlation matrix contains the unnormalized covariance values\n",
    "- [ ] The correlation matrix contains the normalized covariance values\n",
    "- [ ] The covariance matrix contains the variance of the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(wq.corr(),annot=True,linewidths=.5, cmap=\"YlGnBu\", annot_kws={\"fontsize\":8}, vmax=1)\n",
    "plt.title('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7102a15",
   "metadata": {},
   "source": [
    "*******************\n",
    "The correlation matrix is obtained by normalizing the covariance matrix. This normalization involves dividing each element of the covariance matrix by the product of the standard deviations of the two variables corresponding to that element. The result is a matrix of correlation coefficients, where each coefficient is between -1 and 1, representing the linear relationship between the two variables.\n",
    "\n",
    "Therefore, the correlation matrix provides a standardized way of measuring the linear relationship between variables, whereas the covariance matrix measures how much the two variables move in relation to each other. However, since the covariance value is not standardized, it can be difficult to interpret the strength of the relationship between two variables.\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-shelter",
   "metadata": {},
   "source": [
    "### Task 2.1.3 (3 points)\n",
    "\n",
    "In this task, we reason about the covariance matrices.\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> code for normalizing the features of the wine dataset using (1) standard score normalization and (2) range normalization. Finally, (3) plot the **covariance** matrices for\n",
    "1. The unnormalized data\n",
    "2. The [standard score normalized features](https://en.wikipedia.org/wiki/Standard_score)\n",
    "3. The range (min-max) normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9f785",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "\n",
      "\u001b[1;32m/Users/dexterlam/Desktop/Aarhus.Universitet/Kandidat/2.semester/Data mining/DM-Hand-In/handins/handin1.ipynb Cell 44\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n",
      "\n",
      "\u001b[1;32m      <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/Aarhus.Universitet/Kandidat/2.semester/Data%20mining/DM-Hand-In/handins/handin1.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m column_i \u001b[39m=\u001b[39m [row[i] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m X]\n",
      "\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/Aarhus.Universitet/Kandidat/2.semester/Data%20mining/DM-Hand-In/handins/handin1.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m mean_i \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(column_i) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(column_i)\n",
      "\n",
      "\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/Aarhus.Universitet/Kandidat/2.semester/Data%20mining/DM-Hand-In/handins/handin1.ipynb#X53sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m std_i \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39msqrt(\u001b[39msum\u001b[39m([(x \u001b[39m-\u001b[39m mean_i)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m column_i]) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(column_i))\n",
      "\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/Aarhus.Universitet/Kandidat/2.semester/Data%20mining/DM-Hand-In/handins/handin1.ipynb#X53sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m X_mean\u001b[39m.\u001b[39mappend(mean_i)\n",
      "\n",
      "\u001b[1;32m     <a href='vscode-notebook-cell:/Users/dexterlam/Desktop/Aarhus.Universitet/Kandidat/2.semester/Data%20mining/DM-Hand-In/handins/handin1.ipynb#X53sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X_std\u001b[39m.\u001b[39mappend(std_i)\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "X = data_np\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Standard score normalization\n",
    "\n",
    "def standard_score(X):\n",
    "    X_mean = []\n",
    "    X_std = []\n",
    "    for i in range(len(X[0])):\n",
    "        column_i = [row[i] for row in X]\n",
    "        mean_i = sum(column_i) / len(column_i)\n",
    "        std_i = math.sqrt(sum([(x - mean_i)**2 for x in column_i]) / len(column_i))\n",
    "        X_mean.append(mean_i)\n",
    "        X_std.append(std_i)\n",
    "        for j in range(len(X)):\n",
    "            X[j][i] = (X[j][i] - mean_i) / std_i\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Compute the correlation matrix\n",
    "#     n = len(data)\n",
    "#     means = [sum(x) / n for x in data.T]\n",
    "#     stddevs = []\n",
    "#     for i in range(len(data[0])):\n",
    "#         std = [(x[i] - means[i])**2 for x in data]\n",
    "#         stddevs.append((sum(std) / n)**0.5)\n",
    "\n",
    "\n",
    "\n",
    "#     corr = [[0 for _ in range(len(data[0]))] for _ in range(len(data[0]))]\n",
    "\n",
    "\n",
    "#     for i in range(len(data[0])):\n",
    "#         for j in range(len(data[0])):\n",
    "#             if i == j:\n",
    "#                 corr[i][j] = 1\n",
    "#             else:\n",
    "#                 cov = sum((data[k][i] - means[i]) * (data[k][j] - means[j]) for k in range(n)) /n\n",
    "#                 corr[i][j] = cov / (stddevs[i] * stddevs[j])\n",
    "    \n",
    "\n",
    "#     # YOUR CODE HERE \n",
    "#     return corr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Range normalization\n",
    "def range_normalization(X):\n",
    "    X_min = []\n",
    "    X_max = []\n",
    "    for i in range(len(X[0])):\n",
    "        column_i = [row[i] for row in X]\n",
    "        min_i = min(column_i)\n",
    "        max_i = max(column_i)\n",
    "        X_min.append(min_i)\n",
    "        X_max.append(max_i)\n",
    "        for j in range(len(X)):\n",
    "            X[j][i] = (X[j][i] - min_i) / (max_i - min_i)\n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Covariance matrices\n",
    "def covariance_matrix(X):\n",
    "    n_features = len(X[0])\n",
    "    covariance = [[0 for _ in range(n_features)] for _ in range(n_features)]\n",
    "    for i in range(n_features):\n",
    "        for j in range(i, n_features):\n",
    "            mean_i = sum([row[i] for row in X]) / len(X)\n",
    "            mean_j = sum([row[j] for row in X]) / len(X)\n",
    "            covariance_ij = sum([(row[i] - mean_i) * (row[j] - mean_j) for row in X]) / (len(X) - 1)\n",
    "            covariance[i][j] = covariance_ij\n",
    "            covariance[j][i] = covariance_ij\n",
    "    return covariance\n",
    "\n",
    "\n",
    "covariance_unnormalized = covariance_matrix(X)\n",
    "covariance_std = covariance_matrix(X_std)\n",
    "covariance_minmax = covariance_matrix(X_minmax)\n",
    "\n",
    "\n",
    "\n",
    "# Plotting covariance matrices\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(covariance_unnormalized, cmap='hot', interpolation='nearest')\n",
    "plt.title('Unnormalized data')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(covariance_std, cmap='hot', interpolation='nearest')\n",
    "plt.title('Standard score normalized features')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(covariance_minmax, cmap='hot', interpolation='nearest')\n",
    "plt.title('Range (min-max) normalized features')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-decision",
   "metadata": {},
   "source": [
    "### Task 2.1.4 (3 points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span> how the covariance matrix changes with different normalization schemes and reason on why such behaviour appears.\n",
    "You should notice some differences. (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "\n",
    "\n",
    "- [ ] Range normalization preserves the variance. Therefore, features are directly comparable.\n",
    "- [ ] Standard score normalization preserves the variance. Therefore, features are directly comparable.\n",
    "- [ ] Both methods normalize in such a way, that it makes sense to compare the different covariance values to each other.\n",
    "- [ ] None of the methods normalize in such a way that it makes sense to compare the different covariance values to each other.\n",
    "\n",
    "<font color='red'>IMPORTANT: Do NOT just choose one answer. Please clarify WHY this is the correct answer.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-adapter",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-entry",
   "metadata": {},
   "source": [
    "## Task 2.2 Normal distribution\n",
    "### Task 2.2.1 (6 points)\n",
    "Sometimes it is convenient to know whether a variable is close to a normal distribution.\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a method norm_dist that: <br>\n",
    "    \n",
    "1) **Inputs**: \n",
    "    * the number of buckets $b$ \n",
    "    * a vector $x$ of values \n",
    "2) First, compute the histogram of a Gaussian variable with mean $\\mu$ corresponding to the sample mean of $x$ and $\\sigma^2$ corresponding to the sample variance of $x$. Second, calculate the histogram of $x$ using $b$ buckets. \n",
    "3) **Output**: the sum of the absolute differences of the buckets between the two histograms computed in 2). The sum of the differences is computed as \n",
    "$$\\sum_{i=1}^b |H_X(i) - H_{\\mathcal{N}}(i)|$$ \n",
    "where $H_X(i)$ is the i-th bucket of the histogram of $x$ and $H_\\mathcal{N}(i)$ is the i-th bucket of the hisotgram obtained from the normal distribution $\\mathcal{N}(\\mu,\\sigma^2)$. \n",
    "\n",
    "<font color='red'>IMPORTANT: You can use the norm function from Scipy to get the normal distribution to subtract from.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "## Our data comes from the variable X\n",
    "X = data_np\n",
    "def norm_dist(x, b): \n",
    "    dist = 0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "def norm_dist(b, x):\n",
    "    # Compute sample mean and variance\n",
    "    mu = np.mean(x)\n",
    "    var = np.var(x)\n",
    "    # Compute histogram of normal distribution and sample\n",
    "    hist_norm, _ = np.histogram(norm.rvs(loc=mu, scale=np.sqrt(var), size=len(x)), bins=b)\n",
    "    hist_x, _ = np.histogram(x, bins=b)\n",
    "    # Compute absolute differences and sum them up\n",
    "    return np.sum(np.abs(hist_x - hist_norm))\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-mission",
   "metadata": {},
   "source": [
    "### Task 2.2.2 (6 point)\n",
    "A) <span style='color: green'>**\\[Motivate\\]**</span> which drawbacks the method in Task 2.2.1 has. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-sharp",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-blowing",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> whether the method in Task 2.2.1  is robust to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-blade",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-crown",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "C) Run your code on each columns of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-female",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "D) What is the column with the largest distance? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-workplace",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-delay",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "E) Do the attribute features follow a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-match",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-cyprus",
   "metadata": {},
   "source": [
    "### Task 2.2.3 (1 points)\n",
    "\n",
    "Now look at the method below. This is called a Quantile-Quantile [Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot). \n",
    "\n",
    "<span style='color: green'>**\\[Describe\\]**</span> why this method is more robust than the one we proposed in Task 2.2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-battery",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import gridspec\n",
    "\n",
    "plt.tight_layout()\n",
    "_, n = X.shape\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(8, 30))\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=(n-1), figure=fig)\n",
    "for i in np.arange(3,n): \n",
    "    x = toy[headers[i]]\n",
    "    r = i-1\n",
    "    qq = fig.add_subplot(spec[r, 1]) \n",
    "    stats.probplot(x, plot=qq)\n",
    "    h = fig.add_subplot(spec[r, 0])\n",
    "    h.set_title(headers[i])\n",
    "    h.hist(x, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-harbor",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "collaborative-kinase",
   "metadata": {},
   "source": [
    "# Part 3 Cluster Analysis\n",
    "In this section, you will perform cluster analysis of the dataset in Part 2 and modify clustering algorithms to achieve better results. \n",
    "\n",
    "## Task 3.1\n",
    "\n",
    "### Task 3.1.1 (6 points)\n",
    "A)  <span style='color: green'>**\\[Implement\\]**</span> and use the elbow method plotting the **silhouette coefficient** to detect the number of clusters $k$. \n",
    "\n",
    "Use the \"sulphates\" and \"alcohol\" features of the data set. Your final plot should look like the figure below:\n",
    "\n",
    "![SNOWFALL](images/elbow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-bubble",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> your choice of clusters $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-pharmacy",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-mortgage",
   "metadata": {},
   "source": [
    "### Task 3.1.2 (1 points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "Run k-means on the dataset X, with the number of clusters detected in the previous exercise.\n",
    "\n",
    "<font color='red'>IMPORTANT: You can use the KMeans implementation from scikit-learn.</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "# Necessary Data normalization!\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "clusters = []\n",
    "\n",
    "plt.scatter(X_norm[:, 0], X_norm[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-power",
   "metadata": {},
   "source": [
    "### Task 3.1.3 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br> Kernel K-means and the Gaussian Kernel. \n",
    "\n",
    "The Gaussian kernel is defined as in the following equation:\n",
    "\n",
    "$$\n",
    "K\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right)=\\exp \\left(-\\frac{\\left\\|\\mathbf{x}_{i}-\\mathbf{x}_{j}\\right\\|^{2}}{2 \\sigma^{2}}\\right)$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "\n",
    "# Necessary Data normalization!\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=0.8): \n",
    "    k = 0 \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return k\n",
    "\n",
    "\n",
    "def kernel_kmeans(X, n_clusters, kernel=gaussian_kernel, iters=100, error=.01): \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = kernel_kmeans(X_norm, NUMBER_OF_CLUSTERS)\n",
    "\n",
    "scaler = StandardScaler().fit(X_norm)\n",
    "X_scaled = scaler.transform(X_norm)\n",
    "clusters = kernel_kmeans(X_scaled, SOME_AMOUNT_OF_CLUSTERS)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "transparent-junction",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3.2 Clustering quality\n",
    "\n",
    "### Task 3.2.1 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> **Conditional Entropy (CE)** as a measure for clustering quality.\n",
    "\n",
    "Entropy for a clustering is $H(C) = - \\sum_{i=1}^{k}{p_{C_i} \\log {p_{C_i}}}$.\n",
    "\n",
    "The **Conditional Entropy** of $C$ **given** $T$ is given by: \n",
    "$$\\text{CE}(C|T)=-\\sum\\limits^{|C|}_{i=1}\\sum\\limits^{|T|}_{j=1}\\frac{n_{ij}}{n_i}\\log\\frac{n_{ij}}{n_i}$$\n",
    "where $n_{i}$ is the total number of points in cluster $C_i$ and $n_{ij}$ is the number of common points between clusters $C_i$ and $T_j$\n",
    "\n",
    "\n",
    "**Hint**: First implement **Entropy** and then **Conditional Entropy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(C):\n",
    "    # Let C be a list of clusters\n",
    "    entropy = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def CE(C1, C2):\n",
    "    ce = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return ce\n",
    "\n",
    "    \n",
    "\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "\n",
    "# Necessary Data normalization!\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-opportunity",
   "metadata": {},
   "source": [
    "### Task 3.2.2 (3 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span>\n",
    "Plot the Conditional Entropy (implementation from the Task 3.2.1) among the class labels $y$ and the clusters you found with k-means in Task 3.1.1. \n",
    "Make sure that the number of clusters and the number of class labels is the same.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f54924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-pitch",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###YOUR CODE HERE\n",
    "\n",
    "\n",
    "###YOUR CODE HERE\n",
    "class_labels = np.array(toy[\"quality\"])\n",
    "class_labels = [1 if x == 8 else 0 for x in class_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-soundtrack",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "A) Reason about the measure, is the measure influenced by the size of the clusters?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-convert",
   "metadata": {},
   "source": [
    "******************* \n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-police",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Describe\\]**</span><br>\n",
    "B) What does the measure capture? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-settle",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-subject",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2.3 (4 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "Provide an implementation of purity. Recall that purity is the weighted sum of the individual $purity_i = \\frac{1}{|C_i|} \\max_{j=1..k}\\{n_{ij}\\}$ values where $n_{ij}$ is the number of common points in cluster $C_i$\n",
    "and ground-truth cluster $j$ obtained from the labels $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "T = np.array([]) # Ground-truth clusters\n",
    "C = np.array([]) # Clusters obtained by k-means\n",
    "### YOUR CODE HERE\n",
    "\n",
    "## C is the clustering from k-means and T is the ground truth cluster assignments.\n",
    "def purity(C, T):\n",
    "    purity = 0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return purity\n",
    "\n",
    "print('Purity: {}, CE: {}'.format(purity(C,T), CE(C,T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-reform",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2.4 (2 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "\n",
    "Plot the purity of the clusters obtained by k-means in Task 3.1.1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-sector",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Compare purity with **Conditional Entropy (CE)**. Which measure is preferable? (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "- [ ] **CE** is preferable because it uses all the points\n",
    "- [ ] Purity is preferable because it is less computational demanding\n",
    "- [ ] **CE** is preferrable because it does not favor small clusters\n",
    "- [ ] Purity is preferrable because it tends to favor balanced clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-influence",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "generic-state",
   "metadata": {},
   "source": [
    "### Task 3.3 OPTICS\n",
    "\n",
    "### Task 3.3.1 (7 point)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> the OPTICS algorithm\n",
    "\n",
    "If you do not remember [OPTICS](https://en.wikipedia.org/wiki/OPTICS_algorithm), check the slides or the lecture notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdist(x,y,eps,min_samples):\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return rdis\n",
    "\n",
    "def kernel_kmeans(X, eps, min_samples): \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-wireless",
   "metadata": {},
   "source": [
    "### Task 3.3.2 (1 points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "A) Run OPTICS with parameters $\\varepsilon=0.07, minPts=3$. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-forge",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Compare the results of OPTICS with those of k-means. Which of the two methods two achieve a better **CE**? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-candle",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "prostate-residence",
   "metadata": {},
   "source": [
    "### Task 3.3.3 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a simple subspace clustering algorithm.\n",
    "1. Take all subsets of 2,3 attributes. Beware that you should only use the numerical attributes.\n",
    "2. Run OPTICS on each subset. \n",
    "3. Compute **CE** for each subset. \n",
    "4. Keep the k subsets with the largest **CE**. \n",
    "    \n",
    "<font color='red'>IMPORTANT: You may have to experiment a lot with eps and MinPts to get reasonable clusters. You are allowed to use **itertools** library to iterate over all subsets of size 2 and 3.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Data normalization!\n",
    "X_pt = toy.to_numpy()\n",
    "X_norm_pt = (X_pt - X_pt.min(0)) / X_pt.ptp(0) \n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-culture",
   "metadata": {},
   "source": [
    "# Part 4 Outlier detection\n",
    "In this exercise we will work with outlier detection techniques and analyze their performance on the small dataset. Before starting the exercise, run the code below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "\n",
    "X_norm = (X_small - X_small.min(0)) / X_small.ptp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-mumbai",
   "metadata": {},
   "source": [
    "## Task 4.1 (DBoutliers)\n",
    "We will now compare two outlier detection techniques.\n",
    "### Task 4.1.1 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a simple distance-based outlier detector. This is the distance-based outlier detection from the lectures, where a point is considered an outlier if at most a fraction $pi$ of the other points have a distance less of than $eps$ to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBOutliers(X, eps, pi): \n",
    "    outliers = None\n",
    "    ### YOUR STARTS CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-somewhere",
   "metadata": {},
   "source": [
    "### Task 4.1.2 (2 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span>\n",
    "DBOutliers requires tuning the parameters eps, pi. Run the code from Task 4.1.1 with different choices of eps, pi \n",
    "\n",
    "**Note** that the data is normalized. Choose two ranges with **at least** 4 values each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-simulation",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "**Present** the results  and **discuss** how the results vary with respect to (1) eps and (2) pi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-stanford",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-reset",
   "metadata": {},
   "source": [
    "### Task 4.1.3 (3 points)\n",
    "**NOTE** This is hard but also fun. Since it is not impacting the grade too much, you can choose to invent something new.\n",
    "\n",
    "A) Propose and <span style='color: green'>**\\[Implement\\]**</span> a heuristic method to tune parameters eps, pi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_dboutliers(X): \n",
    "    eps = 0\n",
    "    pi = 0\n",
    "    ### YOUR STARTS CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR ENDS CODE HERE\n",
    "    return eps, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-threshold",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Describe\\]**</span> your algorithm, its main idea, its strengths and its weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-progressive",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-hanging",
   "metadata": {},
   "source": [
    "## Task 4.2 LOF (2 points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span><br>\n",
    "Using the parameters eps=0.18, pi=0.2 compare the results of DBOutliers with those obtained by LOF implemented in Week 9. What outliers do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-faith",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "53c6573ba7f8a6e74d7db32f283b0f03dcf3bca683092fd2896b4584a137221f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
