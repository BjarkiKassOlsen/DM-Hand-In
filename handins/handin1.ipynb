{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "overall-spider",
   "metadata": {},
   "source": [
    "# Data Mining - Handin 1 - Clustering \n",
    "Welcome to the handin on clustering algorithms and outlier detection. \n",
    "This handin corresponds to the topics in Week 5--9 in the course.\n",
    "\n",
    "The handin is \n",
    "* done in the chosen handin groups\n",
    "* worth 10% of the final grade\n",
    "\n",
    "For the handin, you will prepare a report in PDF format, by exporting the Jupyter notebook. \n",
    "Please submit\n",
    "1. The jupyter notebook file with your answers\n",
    "2. The PDF obtained by exporting the jupyter notebook\n",
    "\n",
    "Submit both files on Brightspace no later than **March 10th kl. 23:59**.\n",
    "\n",
    "**The grading system**: Tasks are assigned a number of points based on the difficulty and time to solve it. The sum of\n",
    "the number of points is 100. For the maximum grade you need to get at least _80 points_. The minimum grade (02 in the Danish scale)\n",
    "requires **at least** 30 points, with at least 8 points on of the first three Parts (Part 1,2,3) and 6 points in the last part (Part 4).\n",
    "\n",
    "**The exercise types**: There are three different types of exercises\n",
    "1. <span style='color: green'>**\\[Compute by hand\\]**</span> means that you should provide NO code, but show the main steps to reach the result (not all). \n",
    "2. <span style='color: green'>**\\[Motivate\\]**</span> means to provide a short answer of 1-2 lines indicating the main reasoning, e.g., the PageRank of a complete graph is 1/n in all nodes as all nodes are symmetric and are connected one another.\n",
    "3. <span style='color: green'>**\\[Describe\\]**</span> means to provide a potentially longer answer of 1-5 lines indicating the analysis of the data and the results. \n",
    "4. <span style='color: green'>**\\[Prove\\]**</span> means to provide a formal argument and NO code. \n",
    "5. <span style='color: green'>**\\[Implement\\]**</span> means to provide an implementation. Unless otherwise specified, you are allowed to use helper functions (e.g., ```np.mean```, ```itertools.combinations```, and so on). However, if the task is to implement an algorithm, by no means a call to a library that implements the same algorithm will be deemed as sufficient! \n",
    "\n",
    "<font color='red'>**!!! IMPORTANT: YOU ARE NOT ALLOWED TO USE LIBRARY FUNCTIONS (SCIPY, NUMPY etc.) UNLESS EXPLICITY MENTIONED !!!**\n",
    "</font>\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "decimal-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!conda install --yes --prefix {sys.prefix} seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "loaded-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT TOUCH\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN, OPTICS\n",
    "from sklearn.preprocessing import StandardScaler, KBinsDiscretizer\n",
    "import time\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_SEED = 132414\n",
    "## DO NOT TOUCH\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wq = pd.read_csv(\"./data/winequality-red.csv\", sep=';')\n",
    "toy = wq[wq['quality'].isin([4, 8])].sample(n=20, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-regression",
   "metadata": {},
   "source": [
    "# Intro Excercises\n",
    "\n",
    "## Task 1.1 K-Means and DBScan\n",
    "\n",
    "### Task 1.1.1 (5 points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> the cluster assignments _for the dataset below_ using k-means and $k = 2$, with initial centroids being (0, 0) and (1,1)\n",
    "\n",
    "<font color='red'>To evaluate (i.e., only to control the correctness and not to solve the exercise) your results you can use **sklearn.cluster.KMeans**.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "annoying-mapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAa/UlEQVR4nO3de5RV5XnH8e8zFy4CAwKjIhdHKzVBGtROAENICBrktqRJ0SA1Jq601FSjVtskmlU1qSZZqy4bbaiERpaaEO1FCaSAgihFXQEdEBUciVONkUBk5DIMN+f29I/30DkOZ2CGs+fsM2f/PmvtNefs/c5+n83lOe9597vf19wdEREpfEVxByAiIrmhhC8ikhBK+CIiCaGELyKSEEr4IiIJURJ3AMczePBgr6ioiDsMEZFuY+PGjR+4e3mmY3md8CsqKqiqqoo7DBGRbsPM3m3vmLp0REQSIuuEb2bDzew5M6s2s61mdlOGMpPMrM7MNqe2O7KtV0REOieKLp0m4FZ332Rm/YCNZrba3d9oU+55d58ZQX0iInISsm7hu/tOd9+Uel0PVANDsz2viIhEK9I+fDOrAC4ENmQ4fLGZvWpmK83s/CjrlRjs2QObNsGuXXFHIiIdFNkoHTPrCzwB3Ozu+9sc3gSc5e4HzGw68EtgZDvnmQfMAxgxYkRU4UlUWlrg7rvh5z+H4mJobIRZs+AHP4AePeKOTkSOI5IWvpmVEpL9Ynd/su1xd9/v7gdSr1cApWY2ONO53H2hu1e6e2V5ecahpBKnhx8OW58+YSsrgyVL4N57445MRE4gilE6BjwEVLv7fe2UOSNVDjMbm6p3d7Z1SwwWLYLevUPrHqCoCPr1g8WLQ+tfRPJWFF06E4AvA6+b2ebUvtuBEQDuvgCYDXzdzJqAw8Ac10T83dO+fVBa+tF9JSWwfz80NalbRySPZZ3w3f0FwE5Q5sfAj7OtS/LApz8Nq1bBwIGt++rr4ROfULIXyXN60lY655vfDF04e/fCgQPhZ0kJ3HVX3JGJyAnk9Vw6kofOOQdWroRHHoHNm+FjH4OvfCXsF5G8poQvnXfmmXDbbXFHISKdpC4dEZGEUMIXEUkIJXwRkYRQwhcRSQglfBGRhFDCFxFJCCV8EZGEUMIXEUkIJXwRkYRQwhcRSQglfBGRhFDCFxFJCCV8EZGEUMIXEUkIJXwRkYSIYhHz4Wb2nJlVm9lWM7spQxkzswfMrMbMXjOzi7KtV0REOieKBVCagFvdfZOZ9QM2mtlqd38jrcw0YGRqGwc8mPopIiI5knUL3913uvum1Ot6oBoY2qbYLOBRD9YDA8xsSLZ1i4hIx0Xah29mFcCFwIY2h4YC76W9386xHwpHzzHPzKrMrKq2tjbK8EREEi2yhG9mfYEngJvdfX/bwxl+xTOdx90Xunulu1eWl5dHFZ6ISOJFkvDNrJSQ7Be7+5MZimwHhqe9HwbsiKJuERHpmChG6RjwEFDt7ve1U2wZcE1qtM54oM7dd2Zbt4iIdFwUo3QmAF8GXjezzal9twMjANx9AbACmA7UAIeAayOoV0REOiHrhO/uL5C5jz69jAPXZ1uXiIicPD1pKyKSEEr4IiIJoYQvIpIQSvgiIgmhhC8ikhBK+CIiCaGELyKSEEr4IiIJoYQvIpIQSvgiIgmhhC8ikhBK+CIiCaGELyKSEEr4IiIJoYQvIpIQUSyAItKqvh42bYLeveGii6BE/8RE8oX+N0p0nnwSvvMdcA/bqafCokUwalTckYkI6tKRqPzmN/Ctb0FpKfTtC/36wd698NWvQmNj3NGJCBElfDNbZGa7zGxLO8cnmVmdmW1ObXdEUa/kkSVLoLkZevRo3devH+zbBy+9FFtYItIqqi6dh4EfA48ep8zz7j4zovok39TVZd5vBgcP5jYWEckokha+u68D9kRxLummLrkEiopC3/1RjY3hfWVlfHGJyP/LZR/+xWb2qpmtNLPz2ytkZvPMrMrMqmpra3MYnmRl0iSYPDm09Pftgz17Qsv+9tth4MC4oxMRwDy9RZbNicwqgP9299EZjpUBLe5+wMymA/e7+8gTnbOystKrqqoiiU9yoLkZ1qyBlSvDjdvZs2HMmLijEkkUM9vo7hm/VudkWKa77097vcLM/tXMBrv7B7moX7rAO+9ATQ2MGAHnnRf2FRfDlClhE5G8k5OEb2ZnAO+7u5vZWEJX0u5c1C0Ra2iAW26Bp54KD1U1N8O4cfCTn0CfPnFHJyLHEdWwzMeAXwPnmdl2M/uamV1nZteliswGtpjZq8ADwByPqi9JcmvhQlixAsrKQrdNWRm8+CJ8//txRyYiJxBZH35XUB9+Hho3Dg4dgp49W/c1NcHhw1BdHUbqiEhsjteHr/+d0jkHDx6b1IuKQldPU1M8MYlIhyjhS+dMmRImSEu3fz9cfPFHn7IVkbyjhC+d83d/B+XlYZ6cffvCz7594a674o5MRE5As2VK55x5JqxaFWbGfPXVMCRz9uzwISAieU0JXzqvf3+49tq4oxCRTlKXjohIQijhi4gkhBK+iEhCKOGLiCSEEr6ISEIo4YuIJIQSvohIQijhi4gkhBK+iEhCKOGLiCSEEr6ISEIo4YuIJIQSvohIQkS1pu0iM9tlZlvaOW5m9oCZ1ZjZa2Z2URT1iohIx0XVwn8YmHqc49OAkaltHvBgRPWKiEgHRZLw3X0dsOc4RWYBj3qwHhhgZkOiqFtERDomV334Q4H30t5vT+07hpnNM7MqM6uqra3NSXAiIkmQq4RvGfZ5poLuvtDdK929slzL5omIRCZXCX87MDzt/TBgR47qFhERcpfwlwHXpEbrjAfq3H1njuoWEREiWsTczB4DJgGDzWw7cCdQCuDuC4AVwHSgBjgEaAVsEZEciyThu/tVJzjuwPVR1CUiIidHT9qKiCREJC18iY47vPIK/O53cO65cP75YJnGOB0tvGUL/O//QkUFjBlznMIiknRK+Hlk/3649lp47bWQt93hU5+CBQugd+82hQ8dgnnzYMOG1n0XXACLFkG/frkMW0S6CXXp5JG77w6t+7Ky1m3dOpg/P0Ph+++HF18Mhfr3Dz83boQf/jDncYtI96CEnydaWmDJkpC7j/bKmEHfvvD44xl+4fHHQ0s+vXBZGTzxRPhqICLShrp08kRLCzQ3H9sFX1QER45k+IWGBujZ89jCDQ0h4aefqK4ufBsAmDAhfKqISOKohZ8nSkpg4sSQm9PV18P06Rl+YcqU0Omfrq4OJk8Oif+op56C8ePh5pvDNn48rFgRcfQi0h2Y5/HX/8rKSq+qqoo7jJx5912YPRv27g0t/qIiOOMMePJJOO20NoV37oQ//3OorQ1fDYqKYNAg+M//hBEjQpldu+Azn4HS0tZvAx9+GL4FPP98hpOKSHdnZhvdvTLTMXXp5JGzzoI1a2DZMnjrLRg9GmbMgFNOyVB4yBBYvRp+9SuorobzzoOZM0M//lFr1kBjY7gRcFTPnmGEzzPPwNy5XX5NIpI/lPDzTFkZXH11Bwv36QNz5rR//Gh/flstLaGlLyKJoj78QjZxIhQXQ1NT676mprDvs5+NLy4RiYUSfiE75xz4xjfgwAHYvTtsBw6EfeecE3d0IpJj6tIpdDfeGEbuPPVU6N6ZOhX+5E/ijkpEYqCEnwSjR4dNRBJNXToiIgmhhC8ikhBK+CIiCaE+/KRwh9dfh23bYOjQMMVCkT7vRZIkqjVtpwL3A8XAT939h22OTwKWAu+kdj3p7t+Lom7pgCNH4OtfhxdeaN13zjmweDEMHhxfXCKSU1k38cysGJgPTANGAVeZ2agMRZ939wtSm5J9Lv3bv8H//E/r3Pn9+4e5G/7hH+KOTERyKIrv9GOBGnd/290bgMeBWRGcV6Ly2GNhQp70KZMHDAhz8WSce1lEClEUCX8o8F7a++2pfW1dbGavmtlKMzu/vZOZ2TwzqzKzqtra2gjCE5qajp1o/+gaii0t8cQkIjkXRcLPtGp22xm7NgFnufsY4F+AX7Z3Mndf6O6V7l5ZXl4eQXjCzJlhSoV0dXXwyU+2MxWniBSiKBL+dmB42vthwI70Au6+390PpF6vAErNTHcLc+XGG+Hcc0OS370b9u0LXTrf/37ckYlIDkUxSudlYKSZnQ38HpgDfGSidTM7A3jf3d3MxhI+aHZHULd0xIABsHx56LN//XWoqAjLaKXPnS8iBS/rhO/uTWZ2A/A0YVjmInffambXpY4vAGYDXzezJuAwMMfzeamtQtSjR1hNZcaMuCMRkZhoiUMRkQJyvCUO9ailiEhCKOGLiCSE5tKJSX09rF0Lhw/DxRfD8OEn/BURkawo4cdg/Xr4y78M64i7h2egbroJbrgh7shEpJCpSyfHjhyBv/7r8IBr//5hxGSfPnD//fDKK3FHJyKFTAk/xzZsCEk//QHXkhJoboZly+KLS0QKn7p0cqypqf1jjY2tr3fvDhNcNjfDZz4Dp5/e9bGJSGFTws+xceOguDj03/fsGfa1tIS1SKZPD++XL4dbbgn73cOxu+6CuXPbPa2IyAmpSyfH+vaFe++FhgbYswc++CCM2PnSl8Jond274dZbw4OxR/v4e/cOCf/dd+OOXkS6M7XwYzB9OowZAytXwqFDoctmzJgwWmft2tDt07dva/nS0vChsGoV/NVfxRa2iHRzSvgxGTo0DM1sq7k5c3n39o+JiHSEunTyzMSJoc8+/QZuU1MYyTN5cnxxiUj3p4SfZ4YMgTvuCE/g7t4dtoMHw5T2f/zHcUcnIt2ZunTy0NVXw4QJoc++pQUuuUTJXkSyp4Sfp84+OzyRKyISFXXpiIgkhBK+iEhCKOGLiCREJAnfzKaa2TYzqzGzb2c4bmb2QOr4a2Z2URT1iohIx2Wd8M2sGJgPTANGAVeZ2ag2xaYBI1PbPODBbOsVEZHOiaKFPxaocfe33b0BeByY1abMLOBRD9YDA8xsSAR1i4hIB0WR8IcC76W9357a19kyAJjZPDOrMrOq2traCMITERGIJuFbhn1+EmXCTveF7l7p7pXl5eVZByciIkEUCX87kL4E9zBgx0mUERGRLhRFwn8ZGGlmZ5tZD2AO0HaxvmXANanROuOBOnffGUHdIiLSQVlPreDuTWZ2A/A0UAwscvetZnZd6vgCYAUwHagBDgHXZluviIh0TiRz6bj7CkJST9+3IO21A9dHUVd3s20brF8fFjS59NKwipWISBw0eVoXcQ/LEi5e3Lpmba9esGgRjB0bd3QikkSaWqGLrFsXkn1ZGQwcGNambWmB664L69mKiOSaEn4XWbo0tPKL0v6ETzklLGayeXNsYYlIginhd5GWlvaPecYnEEREupYSfhe5/HIw+2jiP3QotPIvvDC+uEQkuZTwu8ikSXDllVBfDx98AHv3hv3z50OPHrGGJiIJpVE6XaSoCO65B+bObR2WOWVKuIErIhIHJfwuZAajR4dNRCRu6tIREUkIJXwRkYRQwhcRSQglfBGRhFDCFxFJCCV8EZGEUMIXEUkIJXwRkYRQwhcRSYisnrQ1s4HAvwMVwG+BK919b4ZyvwXqgWagyd0rs6lXREQ6L9sW/reBNe4+EliTet+ez7n7BUr2IiLxyHYunVnApNTrR4C1wLeyPGdB2LsXVq2Cffvgk58MUyKbxR2ViCRZtgn/dHffCeDuO83stHbKObDKzBz4ibsvzLLevFZVBV/9Khw5Ak1NUFoK06bBP/8zFBfHHZ2IJNUJE76ZPQOckeHQdzpRzwR335H6QFhtZm+6+7p26psHzAMYMWJEJ6rID83N8Dd/E34OGBD2tbTA8uVw2WUwY0as4YlIgp2wD9/dL3X30Rm2pcD7ZjYEIPVzVzvn2JH6uQtYAow9Tn0L3b3S3SvLy8tP5ppitXUr1NVBnz6t+4qKQsv+iSfii0tEJNubtsuAr6RefwVY2raAmfUxs35HXwNTgC1Z1pu3itr5E227oHmheuMNWLAAHn0U/vCHuKMRkXTZ9uH/EPgPM/sa8DvgCgAzOxP4qbtPB04Hlli4Y1kC/MLdn8qy3rw1ahQMHhyWNezXL+xraQkJ/4or4o2tK7nDP/4j/Oxn0NgYvtHccw/cfz9MnRp3dCICYO4edwztqqys9KqqqrjD6LTXXoNrroGDB8NN25IS+OIX4Qc/KNxW/oYN8Bd/ET7kjt6YPnIkfNi99FJY4lFEup6ZbWxv+LuWOOwCn/gEvPACPPtsGJZZWRla/oVs+fKQ3NNHIfXqFRZx37ABLrkkvthEJFDC7yJ9+8Lll8cdRWYtLfDyy2EbNCiMHurU4uoNDbB2LfzmNzBiBHz+85SU9G63uJ4/EMkPSvgJ09QUho0+99xH+9ofeQT+9E87cIK9e+FLX4J33gknKC2F005j5h2/5NFHy2lubm3lHz4cDo8f36WXJCIdVKA9ytKeZctgzRooKws3l089NXwI3HBDaPmf0H33QU0N9O8fTtC/P/zhD1z0X7dz/fVw4ED4TKirCzdyFyyAU07p8ssSkQ5QCz9hliwJLfD0bpa+fWHPHnjzzQ7ca/jVr469A9u/Pzz7LH/7YBNf+EIJL74IvXvD5MmtD5+JSPyU8BMm0ygh97B1aNqHoqJjvwq4//8nSEVF2EQk/6hLJ2GuvDJM+5Ces+vrYcgQGDmyAyeYPTv8Qvpw3rq6MFlQidoPIvlMCT9hpk0LzwTU14e+9v37Qw/Ngw928BmBG2+Eiy4Kv7hnT/j5R38Ed97Z5bGLSHb04FVCVVfDpk3hpu2kSZ28sXr0aaq33grDMj/9aU0DKpIn9OBVFztyJMx9X1MTGru9eoU5Zc48M7Soy8o6f8633w7nbGkJDy2dd160MX/842E7KUVFYaylxluKdCtq4Wfp/ffDHDk7d8KHH4ZejubmMGKxZ88w1cBjj8HHPtbxc/7sZ2FemsbG8L6kJPSkfOMbXXMNIlI4jtfCVx9+lu65B37/+zAyEUKSbm4OD6MOGBDGpd9yy0fvcR7Pjh3wve+FYY2DBoWtTx944IHwYKuIyMlSws+CO6xc2dpls29f6O0oKQkDVyAce+ut8E2gI154IZy3tLR1X0lJeDjq2WcjDV9EEkYJP0vFxa2t9/SHmdJfd3iMO+2XM9N9URHJjhJ+Fszgz/6sdRqBU08NN1mbmsJrCK3+Cy6Aji7eNWlSSOwffti6r6EhtPKnTIk2fhFJFiX8LN12G4weHca1FxWFETqlpeGGbX09nHFGmH6mowYNCoudNzaGD5J9+8IooLvugrPO6qqrEJEk0LDMLPXvD0uXwvr18NvfhmkF+vQJa9uefjpMnAg9enTunNOnhxGPa9eGG8Cf/SycdloXBC8iiaJhmSIi7aipgaefbn0epjssZNRlwzLN7Aoz22pmLWaWsYJUualmts3Maszs29nUKSKSC488EtZjvvfe0C17+eWhu7U7y7YPfwvwRWBdewXMrBiYD0wDRgFXmVk3+JwUkaTasQPuvjt0zx59HqZfP5g/H7Ztizu6k5dVwnf3anc/0eWPBWrc/W13bwAeB2ZlU6+ISFd6/vljn4cpLg4j8J57Lr64spWLUTpDgffS3m9P7cvIzOaZWZWZVdXW1nZ5cCIibbU303dR0Uc/BLqbEyZ8M3vGzLZk2DraSs+0hHW7d4rdfaG7V7p7ZXlHB6+LiEToc58LST/T8zCf/3x8cWXrhMMy3f3SLOvYDgxPez8M2JHlOUVEuszAgfCjH8HNN4fnYCC07u+5J8wI3l3lYhz+y8BIMzsb+D0wB5ibg3pFRE7a1Knw61/DunXheZiJEzv+xHy+yirhm9kXgH8ByoHlZrbZ3S8zszOBn7r7dHdvMrMbgKeBYmCRu2/NOnKR42hoCJPNbd4MQ4fCzJmt012IdNSpp8KsAhpiogevpOAcOABXXQVvvhlGVRQXh2Ucf/GL7vHgjEg2NB++JMpDD8GWLWFq6kGDwroEBw/C3/99x9clEClESvhScJYuDWv0pk9RXVYWWvwffBBfXCJxU8KXglNaemxL3j18ALQ3vlokCZTwpeDMnRuG0qUn/bo6GDdON24l2dTeyYI7bNoEa9aE+e9nzIBzz407Kpk7FzZsgNWrw3uzMHb6n/4p3rhE4qZROifJHe68M4z8aG5uXYLwu98NCUfi98YbYTv9dPjUp7REpCTD8UbpKOGfpI0bYc6cMINeUapjrLERDh8OD2sMGhRvfCKSTBqW2QVWrw5jvIvS/gSP3ix88cX44hIRaY8S/knq1eujw/6OMuv8koYiIrmghH+SZswIfcKNja37Dh8OyX7ixPjiEhFpjxL+SRo5Mty0PXw4DPnbvz+07hcuDKvkiIjkGw3LzMLVV8Nll4WbtEdb9kr2IpKvlPCzVF4eFjcWEcl36tIREUkIJXwRkYRQwhcRSQglfBGRhFDCFxFJiLyeS8fMaoF3444jzWCgEJfQKMTrKsRrAl1XdxLXNZ3l7hmXW8/rhJ9vzKyqvUmJurNCvK5CvCbQdXUn+XhN6tIREUkIJXwRkYRQwu+chXEH0EUK8boK8ZpA19Wd5N01qQ9fRCQh1MIXEUkIJXwRkYRQwu8kM7vCzLaaWYuZ5dWQq84ys6lmts3Maszs23HHEwUzW2Rmu8xsS9yxRMXMhpvZc2ZWnfq3d1PcMUXBzHqZ2Utm9mrqur4bd0xRMbNiM3vFzP477ljSKeF33hbgi8C6uAPJhpkVA/OBacAo4CozGxVvVJF4GJgadxARawJudfePA+OB6wvk7+pDYLK7jwEuAKaa2fh4Q4rMTUB13EG0pYTfSe5e7e7b4o4jAmOBGnd/290bgMeBWTHHlDV3XwfsiTuOKLn7TnfflHpdT0gkQ+ONKnseHEi9LU1t3X4UiZkNA2YAP407lraU8JNrKPBe2vvtFEASKXRmVgFcCGyIOZRIpLo+NgO7gNXuXgjX9SPgm0BLzHEcQwk/AzN7xsy2ZNi6fQs4jWXY1+1bV4XMzPoCTwA3u/v+uOOJgrs3u/sFwDBgrJmNjjmkrJjZTGCXu2+MO5ZMtMRhBu5+adwx5MB2YHja+2HAjphikRMws1JCsl/s7k/GHU/U3H2fma0l3H/pzjfcJwCXm9l0oBdQZmY/d/erY44LUAs/yV4GRprZ2WbWA5gDLIs5JsnAzAx4CKh29/vijicqZlZuZgNSr3sDlwJvxhpUltz9Nncf5u4VhP9Tz+ZLsgcl/E4zsy+Y2XbgYmC5mT0dd0wnw92bgBuApwk3Af/D3bfGG1X2zOwx4NfAeWa23cy+FndMEZgAfBmYbGabU9v0uIOKwBDgOTN7jdAAWe3ueTWMsdBoagURkYRQC19EJCGU8EVEEkIJX0QkIZTwRUQSQglfRCQhlPBFRBJCCV9EJCH+D4slBhoZN31sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "color_map = {4:'Blue', 8:'Red'}\n",
    "X_kmeans = toy[[\"sulphates\", \"alcohol\"]]\n",
    "\n",
    "scaler = StandardScaler().fit(X_kmeans)\n",
    "X_scaled = scaler.transform(X_kmeans)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], alpha=0.8, c=toy['quality'].map(color_map))\n",
    "plt.axis('equal');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "collective-matter",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "We have that, when assigning points to a cluster, it is assigned as follows:\n",
    "\n",
    "$C_i =  \\{x \\in X : \\argmin_{i} ||x - \\mu_i||^2\\}$\n",
    "\n",
    "meaning that, for each point $x \\in X$, we compute the distance to each centroid $\\mu_i$ and assign it to the cluster with the closest centroid. Thus forming the clusters $C_i$, for i assigning all the different clusters.\n",
    "\n",
    "So, for the point in the lower left corner, we have that its coordinates are $p \\approx (-0.869, -1.252)$. We compute the distance to each centroid, and we have that: \n",
    "\n",
    "$||p - \\mu_1||^2 = \\sqrt{(-0.869-0)^2 + (-1.252-0)^2}^2 = (-0.869)^2 + (-1.252)^2 = 2.323$\n",
    "\n",
    "$||p - \\mu_2||^2 = \\sqrt{(-0.869-1)^2 + (-1.252-1)^2}^2 = (-1.869)^2 + (-2.252)^2 = 8.565$\n",
    "\n",
    "So, we assign the point to the cluster with the closest centroid, which is the cluster with centroid $\\mu_1 = (0,0)$, and we have that $C_1 = \\{p\\}$.\n",
    "\n",
    "Then we go through all the other points, to assign them to a cluster. We have that:\n",
    "\n",
    "$C_1 = [(-0.751, -0.545), (-0.456, 0.199), (-0.015, -0.694), (-0.456, -0.843),$\\\n",
    "$(-0.839, -0.843), (-0.604, 0.273), (-0.103, 0.720), (0.280, -0.694), (-0.721, -0.173),$\\\n",
    "$(0.397, -0.619), (-0.780, -0.843), (-0.486, 0.794), (-0.074, 0.497), (-0.280, 0.794),$\\\n",
    "$(1.045, -1.140), (-0.869, -1.252)]$\\\n",
    "$C_2 = [(0.280, 1.389), (0.280, 2.431), (3.754, -0.991), (0.397, 1.538)]$\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d65c9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The points falling in cluster C_1 are:\n",
      " [array([-0.75082858, -0.54497977]), array([-0.456386  ,  0.19901992]), array([-0.01472213, -0.69377971]), array([-0.456386  , -0.84257965]), array([-0.83916135, -0.84257965]), array([-0.60360729,  0.27341989]), array([-0.1030549,  0.7198197]), array([ 0.27972045, -0.69377971]), array([-0.72138432, -0.17297993]), array([ 0.39749748, -0.61937974]), array([-0.78027283, -0.84257965]), array([-0.48583026,  0.79421967]), array([-0.07361064,  0.49661979]), array([-0.27972045,  0.79421967]), array([ 1.04527116, -1.14017952]), array([-0.86860561, -1.25177947])]\n",
      "\n",
      "The points falling in cluster C_2 are:\n",
      " [array([0.27972045, 1.38941942]), array([0.27972045, 2.43101898]), array([ 3.75414288, -0.99137958]), array([0.39749748, 1.53821935])]\n",
      "\n",
      "We get the following labels:\n",
      " [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      " in the same order as the points in X_scaled\n"
     ]
    }
   ],
   "source": [
    "# Setting the initial centroids\n",
    "mu1, mu2 = [0, 0], [1, 1]\n",
    "\n",
    "def clustering_k2(X, mu1, mu2):\n",
    "\n",
    "    # Initializing the clusters\n",
    "    C1, C2 = [], []\n",
    "\n",
    "    # Set an empty list to store the labels\n",
    "    labels = []\n",
    "\n",
    "    # Loop over all the points in X_scaled using the method described above to assing each point to a cluster\n",
    "    for p in X:\n",
    "        # Distance from each centroid\n",
    "        d1 = (p[0] - mu1[0])**2 + (p[1] - mu1[1])**2\n",
    "        d2 = (p[0] - mu2[0])**2 + (p[1] - mu2[1])**2\n",
    "\n",
    "        # Assigning the point to the closest centroid\n",
    "        if d1 < d2:\n",
    "            C1.append(p)\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            C2.append(p)\n",
    "            labels.append(1)\n",
    "        \n",
    "        \n",
    "    print(f'The points falling in cluster C_1 are:\\n {C1}\\n')\n",
    "    print(f'The points falling in cluster C_2 are:\\n {C2}\\n')\n",
    "    print(f'We get the following labels:\\n {labels}\\n in the same order as the points in X_scaled')\n",
    "\n",
    "clustering_k2(X_scaled, mu1, mu2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0c78f88",
   "metadata": {},
   "source": [
    "In order to evaluate the correctness of the results, we can use the sklearn.cluster.KMeans function. Which gives us the following results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "087a919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus we get that the labels are:\n",
      " [0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0]\n",
      " in the same order as the points in X_scaled\n"
     ]
    }
   ],
   "source": [
    "# Assining the initial centroids to be used in the KMeans function below\n",
    "start_centroids = np.array([[0,0], [1,1]])\n",
    "\n",
    "# Setting up the KMeans function\n",
    "Centroids = KMeans(n_clusters=2, init=start_centroids, n_init=1, random_state=RANDOM_SEED)\n",
    "\n",
    "# Fitting the KMeans function to the data\n",
    "Centroids.fit(X_scaled)\n",
    "\n",
    "# Retrieving the labels from the KMeans function\n",
    "print(f'Thus we get that the labels are:\\n {Centroids.labels_}\\n in the same order as the points in X_scaled') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a6af2d3",
   "metadata": {},
   "source": [
    "Thus validating our clustering results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-somerset",
   "metadata": {},
   "source": [
    "### Task 1.1.2 (2 point)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> <br>\n",
    "A) Show two examples with two different initial cluster assignments that lead to a different result. <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "functional-vertex",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "Two examples with two different initial cluster assignments that lead to a different result are:\n",
    "\n",
    "initial_cluster_1 = np.array([[0, 0], [1, 1]])\\\n",
    "initial_cluster_2 = np.array([[0, 0], [4, -1]])\n",
    "\n",
    "To see this, we can run the same function as above, but with the second initial cluster assignment, as we have already seen the results for the first one. Thus we get that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b87926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The points falling in cluster C_1 are:\n",
      " [array([-0.75082858, -0.54497977]), array([-0.456386  ,  0.19901992]), array([-0.01472213, -0.69377971]), array([-0.456386  , -0.84257965]), array([0.27972045, 1.38941942]), array([-0.83916135, -0.84257965]), array([0.27972045, 2.43101898]), array([-0.60360729,  0.27341989]), array([-0.1030549,  0.7198197]), array([ 0.27972045, -0.69377971]), array([-0.72138432, -0.17297993]), array([ 0.39749748, -0.61937974]), array([-0.78027283, -0.84257965]), array([-0.48583026,  0.79421967]), array([-0.07361064,  0.49661979]), array([-0.27972045,  0.79421967]), array([0.39749748, 1.53821935]), array([ 1.04527116, -1.14017952]), array([-0.86860561, -1.25177947])]\n",
      "\n",
      "The points falling in cluster C_2 are:\n",
      " [array([ 3.75414288, -0.99137958])]\n",
      "\n",
      "We get the following labels:\n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      " in the same order as the points in X_scaled\n"
     ]
    }
   ],
   "source": [
    "mu1, mu2 = [0,0], [4, -1]\n",
    "\n",
    "clustering_k2(X_scaled, mu1, mu2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "06d68fc3",
   "metadata": {},
   "source": [
    "Showing that, with the second initial centroid assignment, we only get one point into the second cluster, and the rest of the points are assigned to the first cluster. Thus resulting in a different clustering then the first initilization of the centroids.\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-chicago",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span> <br>\n",
    "B) How you explain the difference between the two cluster assignments in point A)?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "unable-office",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "This difference, is caused by the fact, that our second initialization of the centroids, had the second cluster right next to the one outlier in the dataset. This resulted in all the other point except for the outlier to be assigned to the first cluster. Thus resulting in a different clustering then the first initilization of the centroids.\n",
    "\n",
    "\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "statutory-management",
   "metadata": {},
   "source": [
    "### Task 1.1.3 (5 points)\n",
    "<span style='color: green'>**\\[Compute by hand\\]**</span> the dendrogram for the dataset of Task 1.1.1. using **average-link**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "specified-template",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "Jeg tror at vi skal genskabe plottet nedenfor...\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aba76243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "Z = linkage(X_scaled, 'average')\n",
    "fig = plt.figure(figsize=(25, 10))\n",
    "dn = dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-benjamin",
   "metadata": {},
   "source": [
    "### Task 1.1.4 (2 points)\n",
    "A) <span style='color: green'>**\\[Compute by hand\\]**</span> the density-based clustering for the dataset of Task 1.1.1 using $\\epsilon=0.35$ and $MinPts=3$. Present at least 2 iterations of the algorithm.<br> \n",
    "<font color='red'>**IMPORTANT: For this exercise you can use the DBSCAN from sklearn ONLY TO CHECK YOUR RESULTS**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d48787f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.35\n",
    "minpts = 3\n",
    "\n",
    "X = X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b215cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n",
      "hi\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute by hand the density-based clustering for the dataset of Task 1.1.1 using $\\epsilon = 0.35$ and $MinPts=3$. Present at least 2 iterations of the algorithm.\n",
    "\n",
    "# def DBScan(X, eps, minpts):\n",
    "\n",
    "Clusters = np.zeros(len(X))\n",
    "core_objects = np.zeros(len(X))\n",
    "Next_Cluster = 1\n",
    "\n",
    "for q in range(len(X)):\n",
    "    # print(Clusters[o])\n",
    "    if Clusters[q] == 0:\n",
    "        N_e = 0 # Neighborhood wrt epsilon\n",
    "        for p in range(len(X)):\n",
    "            dist = (X[q][0] - X[p][0])**2 + (X[q][1] - X[p][1])**2\n",
    "\n",
    "            if dist <= eps:\n",
    "                N_e += 1\n",
    "\n",
    "                Clusters[p] = Next_Cluster\n",
    "        \n",
    "        if N_e >= minpts:\n",
    "            Clusters[q] = Next_Cluster\n",
    "            Next_Cluster += 1\n",
    "            core_objects[q] = 1\n",
    "        else:\n",
    "            Clusters[q] = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb1be446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'a': 2, 'a': 3, 'c': 3}\n",
    "\n",
    "test.values() == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-emperor",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-briefs",
   "metadata": {},
   "source": [
    "\n",
    "B) <span style='color: green'>**\\[Describe\\]**</span> the difference between the clusters obtained with DBSCAN and those obtained with KMeans in Task 1.1.1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-programming",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-fields",
   "metadata": {},
   "source": [
    "## Task 1.2 Elliptic data set (2 points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span> <br> \n",
    "After looking at the dataset _below_, you want to detect the red outlier point, assuming you know that it is an outlier. \n",
    "\n",
    "Which approach would be the most obvious to find the red outlier? Please (1) check the box and (2) motivate your answer below:\n",
    "- [ ] Distance based approach (with parameteres $\\pi=0.5$, $\\epsilon=2$ and euclidean distance)\n",
    "- [ ] Angle based approach\n",
    "- [ ] Depth based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspended-legend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D_new = np.array([[1.0, 2.0], # Red \n",
    "                [1., 1.0],\n",
    "                [0.5, 0.5],\n",
    "                [1, 0.5],\n",
    "                [0.5, 1],\n",
    "                [0.75, 0.75]\n",
    "                 ])\n",
    "\n",
    "plt.scatter(D_new[:, 0], D_new[:, 1], alpha=0.8, c = ['red' if i == 0 else 'blue' for i in range(len(D_new))])\n",
    "plt.axis([0, 2, 0,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removable-tuesday",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southeast-extraction",
   "metadata": {},
   "source": [
    "## Task 1.3 Theoretical questions (4 points)\n",
    "<span style='color: green'>**\\[Prove\\]**</span> \n",
    "\n",
    "1. You are given a measure $d(x,y) = |x-y|$, prove that the measure is a metric \n",
    "2. Prove that $\\hat{\\Sigma}=\n",
    "\\frac{1}{n}\\sum_{i=1}^n (x_i -\\hat{\\mu}^\\top)\\cdot(x_i -\\hat{\\mu}^\\top)^\\top=E[(X-\\hat{\\mu})(X-\\hat{\\mu})^\\top]$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "single-column",
   "metadata": {},
   "source": [
    "*******************\n",
    "**Answer**\n",
    "\n",
    "- 1. If $d(\\cdot, \\cdot)$ is a metric, it must satisfy the following axioms for all $p_i$ and $p_j$:\n",
    "\n",
    "a) $d(p_i,p_j) \\ge 0$\\\n",
    "b) $d(p_i,p_j) = 0 \\iff p_i = p_j$\\\n",
    "c) $d(p_i,p_j) = d(p_j,p_i)$\\\n",
    "d) $d(p_i,p_j) \\le d(p_i,p_k) + d(p_k,p_j)$ (the triangle inequality)\n",
    "\n",
    "Thus we need to check if our metric satisfies the criteria's above.\n",
    "\n",
    "a) $d(x,y) = |x-y| \\geq 0 \\quad \\forall x, y$\\\n",
    "b) $d(x,y) = |x-y| = 0 \\iff x = y$\\\n",
    "c) $d(x,y) = |x-y| = |y-x| = d(y,x)$\\\n",
    "d) $d(x,y) = |x-y| = |x-z+z-y| \\leq |x-z| + |z-y| = d(x,z) + d(z,y)$\n",
    "\n",
    "The first two criteria's are trivially satisfied, and the last two are also trivally satisfied by the properties of the absolute value function.\n",
    "\n",
    "- 2. Not sure if we have to prove LLN, or if we just have to show that vector multiplication can be written more compact in expectation form?\n",
    "\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-artwork",
   "metadata": {},
   "source": [
    "# Part 2 Exploratory data analysis\n",
    "In this section, you will perform preliminary analysis on your data. These preliminary analysis are useful to understand how the data behaves, before running complex algorithms.<br>\n",
    "\n",
    "This dataset is about red wine variants of the Portuguese \"Vinho Verde\" wine. It only contains physicochemical and sensory variables, so no prices, grape types and such. Every sample  has also a class of quality which has scores between 1 and 10. It has been used and published with [Cortez et al., 2009](http://dx.doi.org/10.1016/j.dss.2009.05.016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "guilty-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.08</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.086</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.7</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.172</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>8.8</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.088</td>\n",
       "      <td>17.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>4.6</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.054</td>\n",
       "      <td>8.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.56</td>\n",
       "      <td>13.1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.084</td>\n",
       "      <td>11.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "18            7.4             0.590         0.08             4.4      0.086   \n",
       "38            5.7             1.130         0.09             1.5      0.172   \n",
       "41            8.8             0.610         0.30             2.8      0.088   \n",
       "45            4.6             0.520         0.15             2.1      0.054   \n",
       "73            8.3             0.675         0.26             2.1      0.084   \n",
       "\n",
       "    free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "18                  6.0                  29.0   0.9974  3.38       0.50   \n",
       "38                  7.0                  19.0   0.9940  3.50       0.48   \n",
       "41                 17.0                  46.0   0.9976  3.26       0.51   \n",
       "45                  8.0                  65.0   0.9934  3.90       0.56   \n",
       "73                 11.0                  43.0   0.9976  3.31       0.53   \n",
       "\n",
       "    alcohol  quality  \n",
       "18      9.0        4  \n",
       "38      9.8        4  \n",
       "41      9.3        4  \n",
       "45     13.1        4  \n",
       "73      9.2        4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy = wq[wq['quality'].isin([4, 8])]\n",
    "data_np = toy.to_numpy()\n",
    "headers = [\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\",\"quality\"]\n",
    "X = data_np[:,:10]\n",
    "y = data_np[:,11]\n",
    "y = y.astype(int) - 1\n",
    "rows, cols = np.shape(X)\n",
    "toy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-ottawa",
   "metadata": {},
   "source": [
    "## Task 2.1 Correlation matrix\n",
    "### Task 2.1.1 (5 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span> in the code-box below the **correlation matrix** (not covariance matrix) among all the attributes. <br>\n",
    "<font color='red'>To CHECK your results you can use **numpy.corrcoef**.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47cb5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.40000e+00, 5.90000e-01, 8.00000e-02, 4.40000e+00, 8.60000e-02,\n",
       "        6.00000e+00, 2.90000e+01, 9.97400e-01, 3.38000e+00, 5.00000e-01],\n",
       "       [5.70000e+00, 1.13000e+00, 9.00000e-02, 1.50000e+00, 1.72000e-01,\n",
       "        7.00000e+00, 1.90000e+01, 9.94000e-01, 3.50000e+00, 4.80000e-01],\n",
       "       [8.80000e+00, 6.10000e-01, 3.00000e-01, 2.80000e+00, 8.80000e-02,\n",
       "        1.70000e+01, 4.60000e+01, 9.97600e-01, 3.26000e+00, 5.10000e-01],\n",
       "       [4.60000e+00, 5.20000e-01, 1.50000e-01, 2.10000e+00, 5.40000e-02,\n",
       "        8.00000e+00, 6.50000e+01, 9.93400e-01, 3.90000e+00, 5.60000e-01],\n",
       "       [8.30000e+00, 6.75000e-01, 2.60000e-01, 2.10000e+00, 8.40000e-02,\n",
       "        1.10000e+01, 4.30000e+01, 9.97600e-01, 3.31000e+00, 5.30000e-01],\n",
       "       [8.30000e+00, 6.25000e-01, 2.00000e-01, 1.50000e+00, 8.00000e-02,\n",
       "        2.70000e+01, 1.19000e+02, 9.97200e-01, 3.16000e+00, 1.12000e+00],\n",
       "       [5.00000e+00, 1.02000e+00, 4.00000e-02, 1.40000e+00, 4.50000e-02,\n",
       "        4.10000e+01, 8.50000e+01, 9.93800e-01, 3.75000e+00, 4.80000e-01],\n",
       "       [9.20000e+00, 5.20000e-01, 1.00000e+00, 3.40000e+00, 6.10000e-01,\n",
       "        3.20000e+01, 6.90000e+01, 9.99600e-01, 2.74000e+00, 2.00000e+00],\n",
       "       [7.60000e+00, 6.80000e-01, 2.00000e-02, 1.30000e+00, 7.20000e-02,\n",
       "        9.00000e+00, 2.00000e+01, 9.96500e-01, 3.17000e+00, 1.08000e+00],\n",
       "       [7.30000e+00, 5.50000e-01, 3.00000e-02, 1.60000e+00, 7.20000e-02,\n",
       "        1.70000e+01, 4.20000e+01, 9.95600e-01, 3.37000e+00, 4.80000e-01],\n",
       "       [7.90000e+00, 8.85000e-01, 3.00000e-02, 1.80000e+00, 5.80000e-02,\n",
       "        4.00000e+00, 8.00000e+00, 9.97200e-01, 3.36000e+00, 3.30000e-01],\n",
       "       [6.90000e+00, 1.09000e+00, 6.00000e-02, 2.10000e+00, 6.10000e-02,\n",
       "        1.20000e+01, 3.10000e+01, 9.94800e-01, 3.51000e+00, 4.30000e-01],\n",
       "       [8.40000e+00, 6.35000e-01, 3.60000e-01, 2.00000e+00, 8.90000e-02,\n",
       "        1.50000e+01, 5.50000e+01, 9.97450e-01, 3.31000e+00, 5.70000e-01],\n",
       "       [7.00000e+00, 9.75000e-01, 4.00000e-02, 2.00000e+00, 8.70000e-02,\n",
       "        1.20000e+01, 6.70000e+01, 9.95650e-01, 3.35000e+00, 6.00000e-01],\n",
       "       [8.10000e+00, 8.70000e-01, 0.00000e+00, 3.30000e+00, 9.60000e-02,\n",
       "        2.60000e+01, 6.10000e+01, 1.00025e+00, 3.60000e+00, 7.20000e-01],\n",
       "       [7.90000e+00, 3.50000e-01, 4.60000e-01, 3.60000e+00, 7.80000e-02,\n",
       "        1.50000e+01, 3.70000e+01, 9.97300e-01, 3.35000e+00, 8.60000e-01],\n",
       "       [1.03000e+01, 3.20000e-01, 4.50000e-01, 6.40000e+00, 7.30000e-02,\n",
       "        5.00000e+00, 1.30000e+01, 9.97600e-01, 3.23000e+00, 8.20000e-01],\n",
       "       [5.60000e+00, 8.50000e-01, 5.00000e-02, 1.40000e+00, 4.50000e-02,\n",
       "        1.20000e+01, 8.80000e+01, 9.92400e-01, 3.56000e+00, 8.20000e-01],\n",
       "       [1.25000e+01, 4.60000e-01, 4.90000e-01, 4.50000e+00, 7.00000e-02,\n",
       "        2.60000e+01, 4.90000e+01, 9.98100e-01, 3.05000e+00, 5.70000e-01],\n",
       "       [1.26000e+01, 3.10000e-01, 7.20000e-01, 2.20000e+00, 7.20000e-02,\n",
       "        6.00000e+00, 2.90000e+01, 9.98700e-01, 2.88000e+00, 8.20000e-01],\n",
       "       [1.13000e+01, 6.20000e-01, 6.70000e-01, 5.20000e+00, 8.60000e-02,\n",
       "        6.00000e+00, 1.90000e+01, 9.98800e-01, 3.22000e+00, 6.90000e-01],\n",
       "       [9.40000e+00, 3.00000e-01, 5.60000e-01, 2.80000e+00, 8.00000e-02,\n",
       "        6.00000e+00, 1.70000e+01, 9.96400e-01, 3.15000e+00, 9.20000e-01],\n",
       "       [1.07000e+01, 3.50000e-01, 5.30000e-01, 2.60000e+00, 7.00000e-02,\n",
       "        5.00000e+00, 1.60000e+01, 9.97200e-01, 3.15000e+00, 6.50000e-01],\n",
       "       [1.07000e+01, 3.50000e-01, 5.30000e-01, 2.60000e+00, 7.00000e-02,\n",
       "        5.00000e+00, 1.60000e+01, 9.97200e-01, 3.15000e+00, 6.50000e-01],\n",
       "       [1.05000e+01, 5.90000e-01, 4.90000e-01, 2.10000e+00, 7.00000e-02,\n",
       "        1.40000e+01, 4.70000e+01, 9.99100e-01, 3.30000e+00, 5.60000e-01],\n",
       "       [9.90000e+00, 5.00000e-01, 2.40000e-01, 2.30000e+00, 1.03000e-01,\n",
       "        6.00000e+00, 1.40000e+01, 9.97800e-01, 3.34000e+00, 5.20000e-01],\n",
       "       [5.00000e+00, 4.20000e-01, 2.40000e-01, 2.00000e+00, 6.00000e-02,\n",
       "        1.90000e+01, 5.00000e+01, 9.91700e-01, 3.72000e+00, 7.40000e-01],\n",
       "       [8.20000e+00, 9.15000e-01, 2.70000e-01, 2.10000e+00, 8.80000e-02,\n",
       "        7.00000e+00, 2.30000e+01, 9.96200e-01, 3.26000e+00, 4.70000e-01],\n",
       "       [1.01000e+01, 9.35000e-01, 2.20000e-01, 3.40000e+00, 1.05000e-01,\n",
       "        1.10000e+01, 8.60000e+01, 1.00100e+00, 3.43000e+00, 6.40000e-01],\n",
       "       [8.30000e+00, 8.45000e-01, 1.00000e-02, 2.20000e+00, 7.00000e-02,\n",
       "        5.00000e+00, 1.40000e+01, 9.96700e-01, 3.32000e+00, 5.80000e-01],\n",
       "       [7.10000e+00, 8.40000e-01, 2.00000e-02, 4.40000e+00, 9.60000e-02,\n",
       "        5.00000e+00, 1.30000e+01, 9.97000e-01, 3.41000e+00, 5.70000e-01],\n",
       "       [7.50000e+00, 3.80000e-01, 4.80000e-01, 2.60000e+00, 7.30000e-02,\n",
       "        2.20000e+01, 8.40000e+01, 9.97200e-01, 3.32000e+00, 7.00000e-01],\n",
       "       [9.10000e+00, 7.65000e-01, 4.00000e-02, 1.60000e+00, 7.80000e-02,\n",
       "        4.00000e+00, 1.40000e+01, 9.98000e-01, 3.29000e+00, 5.40000e-01],\n",
       "       [7.50000e+00, 1.11500e+00, 1.00000e-01, 3.10000e+00, 8.60000e-02,\n",
       "        5.00000e+00, 1.20000e+01, 9.95800e-01, 3.54000e+00, 6.00000e-01],\n",
       "       [6.90000e+00, 3.90000e-01, 2.40000e-01, 2.10000e+00, 1.02000e-01,\n",
       "        4.00000e+00, 7.00000e+00, 9.94620e-01, 3.44000e+00, 5.80000e-01],\n",
       "       [7.80000e+00, 5.70000e-01, 9.00000e-02, 2.30000e+00, 6.50000e-02,\n",
       "        3.40000e+01, 4.50000e+01, 9.94170e-01, 3.46000e+00, 7.40000e-01],\n",
       "       [7.50000e+00, 6.85000e-01, 7.00000e-02, 2.50000e+00, 5.80000e-02,\n",
       "        5.00000e+00, 9.00000e+00, 9.96320e-01, 3.38000e+00, 5.50000e-01],\n",
       "       [1.16000e+01, 4.70000e-01, 4.40000e-01, 1.60000e+00, 1.47000e-01,\n",
       "        3.60000e+01, 5.10000e+01, 9.98360e-01, 3.38000e+00, 8.60000e-01],\n",
       "       [7.30000e+00, 3.50000e-01, 2.40000e-01, 2.00000e+00, 6.70000e-02,\n",
       "        2.80000e+01, 4.80000e+01, 9.95760e-01, 3.43000e+00, 5.40000e-01],\n",
       "       [7.10000e+00, 4.70000e-01, 0.00000e+00, 2.20000e+00, 6.70000e-02,\n",
       "        7.00000e+00, 1.40000e+01, 9.95170e-01, 3.40000e+00, 5.80000e-01],\n",
       "       [8.40000e+00, 6.70000e-01, 1.90000e-01, 2.20000e+00, 9.30000e-02,\n",
       "        1.10000e+01, 7.50000e+01, 9.97360e-01, 3.20000e+00, 5.90000e-01],\n",
       "       [1.20000e+01, 6.30000e-01, 5.00000e-01, 1.40000e+00, 7.10000e-02,\n",
       "        6.00000e+00, 2.60000e+01, 9.97910e-01, 3.07000e+00, 6.00000e-01],\n",
       "       [9.10000e+00, 4.00000e-01, 5.00000e-01, 1.80000e+00, 7.10000e-02,\n",
       "        7.00000e+00, 1.60000e+01, 9.94620e-01, 3.21000e+00, 6.90000e-01],\n",
       "       [1.00000e+01, 2.60000e-01, 5.40000e-01, 1.90000e+00, 8.30000e-02,\n",
       "        4.20000e+01, 7.40000e+01, 9.94510e-01, 2.98000e+00, 6.30000e-01],\n",
       "       [7.90000e+00, 5.40000e-01, 3.40000e-01, 2.50000e+00, 7.60000e-02,\n",
       "        8.00000e+00, 1.70000e+01, 9.92350e-01, 3.20000e+00, 7.20000e-01],\n",
       "       [6.50000e+00, 5.80000e-01, 0.00000e+00, 2.20000e+00, 9.60000e-02,\n",
       "        3.00000e+00, 1.30000e+01, 9.95570e-01, 3.62000e+00, 6.20000e-01],\n",
       "       [6.50000e+00, 8.80000e-01, 3.00000e-02, 5.60000e+00, 7.90000e-02,\n",
       "        2.30000e+01, 4.70000e+01, 9.95720e-01, 3.58000e+00, 5.00000e-01],\n",
       "       [8.80000e+00, 9.55000e-01, 5.00000e-02, 1.80000e+00, 7.50000e-02,\n",
       "        5.00000e+00, 1.90000e+01, 9.96160e-01, 3.30000e+00, 4.40000e-01],\n",
       "       [8.60000e+00, 4.20000e-01, 3.90000e-01, 1.80000e+00, 6.80000e-02,\n",
       "        6.00000e+00, 1.20000e+01, 9.95160e-01, 3.35000e+00, 6.90000e-01],\n",
       "       [1.02000e+01, 2.30000e-01, 3.70000e-01, 2.20000e+00, 5.70000e-02,\n",
       "        1.40000e+01, 3.60000e+01, 9.96140e-01, 3.23000e+00, 4.90000e-01],\n",
       "       [6.00000e+00, 3.30000e-01, 3.20000e-01, 1.29000e+01, 5.40000e-02,\n",
       "        6.00000e+00, 1.13000e+02, 9.95720e-01, 3.30000e+00, 5.60000e-01],\n",
       "       [8.10000e+00, 7.30000e-01, 0.00000e+00, 2.50000e+00, 8.10000e-02,\n",
       "        1.20000e+01, 2.40000e+01, 9.97980e-01, 3.38000e+00, 4.60000e-01],\n",
       "       [6.50000e+00, 6.70000e-01, 0.00000e+00, 4.30000e+00, 5.70000e-02,\n",
       "        1.10000e+01, 2.00000e+01, 9.94880e-01, 3.45000e+00, 5.60000e-01],\n",
       "       [6.30000e+00, 1.02000e+00, 0.00000e+00, 2.00000e+00, 8.30000e-02,\n",
       "        1.70000e+01, 2.40000e+01, 9.94370e-01, 3.59000e+00, 5.50000e-01],\n",
       "       [8.20000e+00, 7.80000e-01, 0.00000e+00, 2.20000e+00, 8.90000e-02,\n",
       "        1.30000e+01, 2.60000e+01, 9.97800e-01, 3.37000e+00, 4.60000e-01],\n",
       "       [5.50000e+00, 4.90000e-01, 3.00000e-02, 1.80000e+00, 4.40000e-02,\n",
       "        2.80000e+01, 8.70000e+01, 9.90800e-01, 3.50000e+00, 8.20000e-01],\n",
       "       [8.50000e+00, 4.00000e-01, 4.00000e-01, 6.30000e+00, 5.00000e-02,\n",
       "        3.00000e+00, 1.00000e+01, 9.95660e-01, 3.28000e+00, 5.60000e-01],\n",
       "       [7.50000e+00, 7.55000e-01, 0.00000e+00, 1.90000e+00, 8.40000e-02,\n",
       "        6.00000e+00, 1.20000e+01, 9.96720e-01, 3.34000e+00, 4.90000e-01],\n",
       "       [6.80000e+00, 6.80000e-01, 9.00000e-02, 3.90000e+00, 6.80000e-02,\n",
       "        1.50000e+01, 2.90000e+01, 9.95240e-01, 3.41000e+00, 5.20000e-01],\n",
       "       [8.00000e+00, 8.30000e-01, 2.70000e-01, 2.00000e+00, 8.00000e-02,\n",
       "        1.10000e+01, 6.30000e+01, 9.96520e-01, 3.29000e+00, 4.80000e-01],\n",
       "       [6.60000e+00, 6.10000e-01, 0.00000e+00, 1.60000e+00, 6.90000e-02,\n",
       "        4.00000e+00, 8.00000e+00, 9.93960e-01, 3.33000e+00, 3.70000e-01],\n",
       "       [7.20000e+00, 3.30000e-01, 3.30000e-01, 1.70000e+00, 6.10000e-02,\n",
       "        3.00000e+00, 1.30000e+01, 9.96000e-01, 3.23000e+00, 1.10000e+00],\n",
       "       [6.40000e+00, 5.30000e-01, 9.00000e-02, 3.90000e+00, 1.23000e-01,\n",
       "        1.40000e+01, 3.10000e+01, 9.96800e-01, 3.50000e+00, 6.70000e-01],\n",
       "       [7.20000e+00, 3.80000e-01, 3.10000e-01, 2.00000e+00, 5.60000e-02,\n",
       "        1.50000e+01, 2.90000e+01, 9.94720e-01, 3.23000e+00, 7.60000e-01],\n",
       "       [6.20000e+00, 7.85000e-01, 0.00000e+00, 2.10000e+00, 6.00000e-02,\n",
       "        6.00000e+00, 1.30000e+01, 9.96640e-01, 3.59000e+00, 6.10000e-01],\n",
       "       [6.70000e+00, 1.04000e+00, 8.00000e-02, 2.30000e+00, 6.70000e-02,\n",
       "        1.90000e+01, 3.20000e+01, 9.96480e-01, 3.52000e+00, 5.70000e-01],\n",
       "       [5.60000e+00, 6.20000e-01, 3.00000e-02, 1.50000e+00, 8.00000e-02,\n",
       "        6.00000e+00, 1.30000e+01, 9.94980e-01, 3.66000e+00, 6.20000e-01],\n",
       "       [7.20000e+00, 5.80000e-01, 5.40000e-01, 2.10000e+00, 1.14000e-01,\n",
       "        3.00000e+00, 9.00000e+00, 9.97190e-01, 3.33000e+00, 5.70000e-01],\n",
       "       [6.80000e+00, 9.10000e-01, 6.00000e-02, 2.00000e+00, 6.00000e-02,\n",
       "        4.00000e+00, 1.10000e+01, 9.95920e-01, 3.53000e+00, 6.40000e-01],\n",
       "       [6.90000e+00, 4.80000e-01, 2.00000e-01, 1.90000e+00, 8.20000e-02,\n",
       "        9.00000e+00, 2.30000e+01, 9.95850e-01, 3.39000e+00, 4.30000e-01],\n",
       "       [7.40000e+00, 3.60000e-01, 3.00000e-01, 1.80000e+00, 7.40000e-02,\n",
       "        1.70000e+01, 2.40000e+01, 9.94190e-01, 3.24000e+00, 7.00000e-01]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_matrix(X):\n",
    "    corr = None\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    \n",
    "    # YOUR CODE HERE \n",
    "    return corr\n",
    "    \n",
    "X = data_np\n",
    "Corr = correlation_matrix(X)\n",
    "plt.matshow(Corr)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-volume",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "B) By observing the  **correlation matrix** in point A), which pair of different attributes has the highest correlation? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-silver",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-senator",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "C) What does it mean that two attributs are highly correlated? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-breath",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-springfield",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "D) Based on the attributes of the data in Part 2 and your answer in C), did you expect the observation of B)? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-weekly",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-content",
   "metadata": {},
   "source": [
    "### Task 2.1.2 (1 points)\n",
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Plot the correlation matrix running the code below.\n",
    "What is the relationship between the correlation matrix and the covariance matrix? (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "- [ ] The correlation matrix contains the unnormalized covariance values\n",
    "- [ ] The correlation matrix contains the normalized covariance values\n",
    "- [ ] The covariance matrix contains the variance of the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(wq.corr(),annot=True,linewidths=.5, cmap=\"YlGnBu\", annot_kws={\"fontsize\":8}, vmax=1)\n",
    "plt.title('Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-behalf",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-shelter",
   "metadata": {},
   "source": [
    "### Task 2.1.3 (3 points)\n",
    "\n",
    "In this task, we reason about the covariance matrices.\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> code for normalizing the features of the wine dataset using (1) standard score normalization and (2) range normalization. Finally, (3) plot the **covariance** matrices for\n",
    "1. The unnormalized data\n",
    "2. The [standard score normalized features](https://en.wikipedia.org/wiki/Standard_score)\n",
    "3. The range (min-max) normalized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = data_np\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-decision",
   "metadata": {},
   "source": [
    "### Task 2.1.4 (3 points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span> how the covariance matrix changes with different normalization schemes and reason on why such behaviour appears.\n",
    "You should notice some differences. (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "\n",
    "\n",
    "- [ ] Range normalization preserves the variance. Therefore, features are directly comparable.\n",
    "- [ ] Standard score normalization preserves the variance. Therefore, features are directly comparable.\n",
    "- [ ] Both methods normalize in such a way, that it makes sense to compare the different covariance values to each other.\n",
    "- [ ] None of the methods normalize in such a way that it makes sense to compare the different covariance values to each other.\n",
    "\n",
    "<font color='red'>IMPORTANT: Do NOT just choose one answer. Please clarify WHY this is the correct answer.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-adapter",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-entry",
   "metadata": {},
   "source": [
    "## Task 2.2 Normal distribution\n",
    "### Task 2.2.1 (6 points)\n",
    "Sometimes it is convenient to know whether a variable is close to a normal distribution.\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a method norm_dist that: <br>\n",
    "    \n",
    "1) **Inputs**: \n",
    "    * the number of buckets $b$ \n",
    "    * a vector $x$ of values \n",
    "2) First, compute the histogram of a Gaussian variable with mean $\\mu$ corresponding to the sample mean of $x$ and $\\sigma^2$ corresponding to the sample variance of $x$. Second, calculate the histogram of $x$ using $b$ buckets. \n",
    "3) **Output**: the sum of the absolute differences of the buckets between the two histograms computed in 2). The sum of the differences is computed as \n",
    "$$\\sum_{i=1}^b |H_X(i) - H_{\\mathcal{N}}(i)|$$ \n",
    "where $H_X(i)$ is the i-th bucket of the histogram of $x$ and $H_\\mathcal{N}(i)$ is the i-th bucket of the hisotgram obtained from the normal distribution $\\mathcal{N}(\\mu,\\sigma^2)$. \n",
    "\n",
    "<font color='red'>IMPORTANT: You can use the norm function from Scipy to get the normal distribution to subtract from.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "## Our data comes from the variable X\n",
    "X = data_np\n",
    "def norm_dist(x, b): \n",
    "    dist = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-mission",
   "metadata": {},
   "source": [
    "### Task 2.2.2 (6 point)\n",
    "A) <span style='color: green'>**\\[Motivate\\]**</span> which drawbacks the method in Task 2.2.1 has. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-sharp",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-blowing",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> whether the method in Task 2.2.1  is robust to outliers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-blade",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-crown",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "C) Run your code on each columns of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-female",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "D) What is the column with the largest distance? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-workplace",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-delay",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "E) Do the attribute features follow a normal distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-match",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-cyprus",
   "metadata": {},
   "source": [
    "### Task 2.2.3 (1 points)\n",
    "\n",
    "Now look at the method below. This is called a Quantile-Quantile [Q-Q plot](https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot). \n",
    "\n",
    "<span style='color: green'>**\\[Describe\\]**</span> why this method is more robust than the one we proposed in Task 2.2.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-battery",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import gridspec\n",
    "\n",
    "plt.tight_layout()\n",
    "_, n = X.shape\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(8, 30))\n",
    "spec = gridspec.GridSpec(ncols=2, nrows=(n-1), figure=fig)\n",
    "for i in np.arange(3,n): \n",
    "    x = toy[headers[i]]\n",
    "    r = i-1\n",
    "    qq = fig.add_subplot(spec[r, 1]) \n",
    "    stats.probplot(x, plot=qq)\n",
    "    h = fig.add_subplot(spec[r, 0])\n",
    "    h.set_title(headers[i])\n",
    "    h.hist(x, bins = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-harbor",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "collaborative-kinase",
   "metadata": {},
   "source": [
    "# Part 3 Cluster Analysis\n",
    "In this section, you will perform cluster analysis of the dataset in Part 2 and modify clustering algorithms to achieve better results. \n",
    "\n",
    "## Task 3.1\n",
    "\n",
    "### Task 3.1.1 (6 points)\n",
    "A)  <span style='color: green'>**\\[Implement\\]**</span> and use the elbow method plotting the **silhouette coefficient** to detect the number of clusters $k$. \n",
    "\n",
    "Use the \"sulphates\" and \"alcohol\" features of the data set. Your final plot should look like the figure below:\n",
    "\n",
    "![SNOWFALL](images/elbow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passive-bubble",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span> your choice of clusters $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-pharmacy",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-mortgage",
   "metadata": {},
   "source": [
    "### Task 3.1.2 (1 points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "Run k-means on the dataset X, with the number of clusters detected in the previous exercise.\n",
    "\n",
    "<font color='red'>IMPORTANT: You can use the KMeans implementation from scikit-learn.</font> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "# Necessary Data normalization!\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)\n",
    "\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "clusters = []\n",
    "\n",
    "plt.scatter(X_norm[:, 0], X_norm[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-power",
   "metadata": {},
   "source": [
    "### Task 3.1.3 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br> Kernel K-means and the Gaussian Kernel. \n",
    "\n",
    "The Gaussian kernel is defined as in the following equation:\n",
    "\n",
    "$$\n",
    "K\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}\\right)=\\exp \\left(-\\frac{\\left\\|\\mathbf{x}_{i}-\\mathbf{x}_{j}\\right\\|^{2}}{2 \\sigma^{2}}\\right)$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "\n",
    "# Necessary Data normalization!\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)\n",
    "\n",
    "def gaussian_kernel(x, y, sigma=0.8): \n",
    "    k = 0 \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return k\n",
    "\n",
    "\n",
    "def kernel_kmeans(X, n_clusters, kernel=gaussian_kernel, iters=100, error=.01): \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = kernel_kmeans(X_norm, NUMBER_OF_CLUSTERS)\n",
    "\n",
    "scaler = StandardScaler().fit(X_norm)\n",
    "X_scaled = scaler.transform(X_norm)\n",
    "clusters = kernel_kmeans(X_scaled, SOME_AMOUNT_OF_CLUSTERS)\n",
    "\n",
    "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], alpha=0.8, c=clusters)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "transparent-junction",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3.2 Clustering quality\n",
    "\n",
    "### Task 3.2.1 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> **Conditional Entropy (CE)** as a measure for clustering quality.\n",
    "\n",
    "Entropy for a clustering is $H(C) = - \\sum_{i=1}^{k}{p_{C_i} \\log {p_{C_i}}}$.\n",
    "\n",
    "The **Conditional Entropy** of $C$ **given** $T$ is given by: \n",
    "$$\\text{CE}(C|T)=-\\sum\\limits^{|C|}_{i=1}\\sum\\limits^{|T|}_{j=1}\\frac{n_{ij}}{n_i}\\log\\frac{n_{ij}}{n_i}$$\n",
    "where $n_{i}$ is the total number of points in cluster $C_i$ and $n_{ij}$ is the number of common points between clusters $C_i$ and $T_j$\n",
    "\n",
    "\n",
    "**Hint**: First implement **Entropy** and then **Conditional Entropy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(C):\n",
    "    # Let C be a list of clusters\n",
    "    entropy = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def CE(C1, C2):\n",
    "    ce = 0\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return ce\n",
    "\n",
    "    \n",
    "\n",
    "X = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "\n",
    "# Necessary Data normalization!\n",
    "X_norm = (X - X.min(0)) / X.ptp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-opportunity",
   "metadata": {},
   "source": [
    "### Task 3.2.2 (3 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span>\n",
    "Plot the Conditional Entropy (implementation from the Task 3.2.1) among the class labels $y$ and the clusters you found with k-means in Task 3.1.1. \n",
    "Make sure that the number of clusters and the number of class labels is the same.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-pitch",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "###YOUR CODE HERE\n",
    "\n",
    "\n",
    "###YOUR CODE HERE\n",
    "class_labels = np.array(toy[\"quality\"])\n",
    "class_labels = [1 if x == 8 else 0 for x in class_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-soundtrack",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "A) Reason about the measure, is the measure influenced by the size of the clusters?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-convert",
   "metadata": {},
   "source": [
    "******************* \n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informational-police",
   "metadata": {},
   "source": [
    "<span style='color: green'>**\\[Describe\\]**</span><br>\n",
    "B) What does the measure capture? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understanding-settle",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-subject",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2.3 (4 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "Provide an implementation of purity. Recall that purity is the weighted sum of the individual $purity_i = \\frac{1}{|C_i|} \\max_{j=1..k}\\{n_{ij}\\}$ values where $n_{ij}$ is the number of common points in cluster $C_i$\n",
    "and ground-truth cluster $j$ obtained from the labels $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "T = np.array([]) # Ground-truth clusters\n",
    "C = np.array([]) # Clusters obtained by k-means\n",
    "### YOUR CODE HERE\n",
    "\n",
    "## C is the clustering from k-means and T is the ground truth cluster assignments.\n",
    "def purity(C, T):\n",
    "    purity = 0\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return purity\n",
    "\n",
    "print('Purity: {}, CE: {}'.format(purity(C,T), CE(C,T)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-reform",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Task 3.2.4 (2 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "\n",
    "Plot the purity of the clusters obtained by k-means in Task 3.1.1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-sector",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Compare purity with **Conditional Entropy (CE)**. Which measure is preferable? (1) Check the correct box below and (2) motivate your answer.\n",
    "\n",
    "- [ ] **CE** is preferable because it uses all the points\n",
    "- [ ] Purity is preferable because it is less computational demanding\n",
    "- [ ] **CE** is preferrable because it does not favor small clusters\n",
    "- [ ] Purity is preferrable because it tends to favor balanced clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-influence",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "generic-state",
   "metadata": {},
   "source": [
    "### Task 3.3 OPTICS\n",
    "\n",
    "### Task 3.3.1 (7 point)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> the OPTICS algorithm\n",
    "\n",
    "If you do not remember [OPTICS](https://en.wikipedia.org/wiki/OPTICS_algorithm), check the slides or the lecture notes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdist(x,y,eps,min_samples):\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return rdis\n",
    "\n",
    "def kernel_kmeans(X, eps, min_samples): \n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-wireless",
   "metadata": {},
   "source": [
    "### Task 3.3.2 (1 points)\n",
    "\n",
    "<span style='color: green'>**\\[Implement\\]**</span><br>\n",
    "A) Run OPTICS with parameters $\\varepsilon=0.07, minPts=3$. <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imposed-forge",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "Compare the results of OPTICS with those of k-means. Which of the two methods two achieve a better **CE**? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-candle",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "prostate-residence",
   "metadata": {},
   "source": [
    "### Task 3.3.3 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a simple subspace clustering algorithm.\n",
    "1. Take all subsets of 2,3 attributes. Beware that you should only use the numerical attributes.\n",
    "2. Run OPTICS on each subset. \n",
    "3. Compute **CE** for each subset. \n",
    "4. Keep the k subsets with the largest **CE**. \n",
    "    \n",
    "<font color='red'>IMPORTANT: You may have to experiment a lot with eps and MinPts to get reasonable clusters. You are allowed to use **itertools** library to iterate over all subsets of size 2 and 3.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Data normalization!\n",
    "X_pt = toy.to_numpy()\n",
    "X_norm_pt = (X_pt - X_pt.min(0)) / X_pt.ptp(0) \n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-culture",
   "metadata": {},
   "source": [
    "# Part 4 Outlier detection\n",
    "In this exercise we will work with outlier detection techniques and analyze their performance on the small dataset. Before starting the exercise, run the code below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-isolation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = toy[[\"sulphates\", \"alcohol\"]].to_numpy()\n",
    "\n",
    "X_norm = (X_small - X_small.min(0)) / X_small.ptp(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-mumbai",
   "metadata": {},
   "source": [
    "## Task 4.1 (DBoutliers)\n",
    "We will now compare two outlier detection techniques.\n",
    "### Task 4.1.1 (6 points)\n",
    "<span style='color: green'>**\\[Implement\\]**</span> a simple distance-based outlier detector. This is the distance-based outlier detection from the lectures, where a point is considered an outlier if at most a fraction $pi$ of the other points have a distance less of than $eps$ to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-ownership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DBOutliers(X, eps, pi): \n",
    "    outliers = None\n",
    "    ### YOUR STARTS CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR CODE ENDS HERE\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-somewhere",
   "metadata": {},
   "source": [
    "### Task 4.1.2 (2 points)\n",
    "A) <span style='color: green'>**\\[Implement\\]**</span>\n",
    "DBOutliers requires tuning the parameters eps, pi. Run the code from Task 4.1.1 with different choices of eps, pi \n",
    "\n",
    "**Note** that the data is normalized. Choose two ranges with **at least** 4 values each.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-simulation",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Motivate\\]**</span><br>\n",
    "\n",
    "**Present** the results  and **discuss** how the results vary with respect to (1) eps and (2) pi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-stanford",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-reset",
   "metadata": {},
   "source": [
    "### Task 4.1.3 (3 points)\n",
    "**NOTE** This is hard but also fun. Since it is not impacting the grade too much, you can choose to invent something new.\n",
    "\n",
    "A) Propose and <span style='color: green'>**\\[Implement\\]**</span> a heuristic method to tune parameters eps, pi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_dboutliers(X): \n",
    "    eps = 0\n",
    "    pi = 0\n",
    "    ### YOUR STARTS CODE HERE\n",
    "    \n",
    "    \n",
    "    ### YOUR ENDS CODE HERE\n",
    "    return eps, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-threshold",
   "metadata": {},
   "source": [
    "B) <span style='color: green'>**\\[Describe\\]**</span> your algorithm, its main idea, its strengths and its weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-progressive",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-hanging",
   "metadata": {},
   "source": [
    "## Task 4.2 LOF (2 points)\n",
    "<span style='color: green'>**\\[Describe\\]**</span><br>\n",
    "Using the parameters eps=0.18, pi=0.2 compare the results of DBOutliers with those obtained by LOF implemented in Week 9. What outliers do you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-faith",
   "metadata": {},
   "source": [
    "*******************\n",
    "**YOUR ANSWER HERE**\n",
    "******************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "53c6573ba7f8a6e74d7db32f283b0f03dcf3bca683092fd2896b4584a137221f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
